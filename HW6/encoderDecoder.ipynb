{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YId1X55ZPDWB"
      },
      "source": [
        "# Neural Machine Translation using Seq2Seq Models\n",
        "\n",
        "In HW06, we will be training our own machine translation system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQy46o98kAfC",
        "outputId": "fdb8e0c2-594b-4782-e297-f029b66d4dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.2-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00jNulTjyG72"
      },
      "source": [
        "Mount your google drive here. We will be storing our training data in the google drive folder named `hw06_data`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuV8pGgTzrCs",
        "outputId": "166c3f14-4ecc-451f-abf7-2aa9d30ef917"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu9aGskp58pS"
      },
      "source": [
        "Make sure you are using a GPU. Go to Runtime -> Change Runtime Type -> GPU.\n",
        "\n",
        "After running the below cell, if your notebook is configured to run on GPU, you should see a `device(type='cuda')` output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2QfJZy3cygL",
        "outputId": "4e9ae379-e7b1-424f-af10-50f63c570c60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchmetrics\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFriOo4dyVC-"
      },
      "source": [
        "Object to store our language data. In this object, we assign a unique integer ID to every word in the vocab. We also assign new `<SOS>`, `<EOS>` and `<OOV>` tokens for start-of-sentence, end-of-sentence and out-of-vocab tokens respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ltOnXrFfbWw"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "OOV_token = 2\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"OOV\"}\n",
        "        self.n_words = 3  # Count SOS, EOS and OOV\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWx_Z9qmyo1V"
      },
      "source": [
        "Standard text pre-processing and string normalization. We convert unicode to ASCII and remove all punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GGfRHOH6feMG"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove punctuations\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TCzbE1VPfg2q"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, path_to_corpus):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open(path_to_corpus, encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('|||')] for l in lines]\n",
        "        \n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG06QhOJyxTS"
      },
      "source": [
        "We only consider sentences that are max 10 words in length. Think about why we might need to restrict the maximum number of words in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6x3izAOAfsF1"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdCG4j2Oy-1b"
      },
      "source": [
        "Read in the data. Ensure that the path to the data files are correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zTXiyj7fw-y",
        "outputId": "c86d1671-ddd5-4aed-ced3-b4875ccc3be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 18798 sentence pairs\n",
            "Trimmed to 4493 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "en 4162\n",
            "hi 4809\n",
            "Reading lines...\n",
            "Read 5534 sentence pairs\n",
            "Trimmed to 2142 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "en 2906\n",
            "zh 2395\n",
            "['and what about the sony pictures cyberhacking', 'और सोनी पिकचर की हकिग']\n",
            "['it frees us from the constraints of our imagination', '佢釋放我們 幻想上嘅限制']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, path_to_corpus):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, path_to_corpus)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "# Give your input path here\n",
        "HI_PATH = \"/content/drive/MyDrive/hw06_data/eng_hin/ted-train.orig.eng-hin\"\n",
        "ZH_PATH = \"/content/drive/MyDrive/hw06_data/eng_zh/ted-train.orig.eng-zh\"\n",
        "input_lang_train_en_hi, output_lang_train_hi, train_pairs_hi = prepareData('en', 'hi', HI_PATH)\n",
        "input_lang_train_en_zh, output_lang_train_zh, train_pairs_zh = prepareData('en', 'zh', ZH_PATH)\n",
        "print(random.choice(train_pairs_hi))\n",
        "print(random.choice(train_pairs_zh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BVBkJVczD3D"
      },
      "source": [
        "Design your encoder model here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rk_1ZuLWj5N9"
      },
      "outputs": [],
      "source": [
        "# Set your hidden size here\n",
        "HIDDEN_SIZE = 256\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        # Assign hidden_size\n",
        "        self.hidden_size = hidden_size##YOUR CODE HERE\n",
        "\n",
        "        # Create nn.Embedding layer with (input_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size) ##YOUR CODE HERE\n",
        "\n",
        "        # Create nn.GRU layer with (hidden_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)##YOUR CODE HERE\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # Run the input through the embedding layer\n",
        "        embedded = self.embedding(input)##YOUR CODE HERE\n",
        "\n",
        "        # Reshape with (1, 1, -1)\n",
        "        embedded = embedded.reshape(1, 1, -1)##YOUR CODE HERE\n",
        "\n",
        "        # Run both the embedded and hidden through GRU\n",
        "        output, hidden = self.gru(embedded, hidden)##YOUR CODE HERE\n",
        "\n",
        "        # Return both output and hidden\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        # Create a torch tensor of zeros of shape (1, 1, HIDDEN_SIZE)\n",
        "        return torch.zeros(1, 1, self.hidden_size).to(device) ##YOUR CODE HERE\n",
        "\n",
        "dummy_in = torch.randint(1, 10, (1,), device=device)\n",
        "dummy_encoder = EncoderRNN(100, HIDDEN_SIZE).to(device)\n",
        "assert dummy_encoder.initHidden().shape == (1, 1, HIDDEN_SIZE)\n",
        "dummy_out, dummy_hid = dummy_encoder.forward(dummy_in, dummy_encoder.initHidden())\n",
        "assert dummy_out.shape == (1, 1, HIDDEN_SIZE)\n",
        "assert dummy_hid.shape == (1, 1, HIDDEN_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ekxl5MczGpy"
      },
      "source": [
        "Design your decoder model here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lxuXcv_4kgLk"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # Assign hidden_size\n",
        "        self.hidden_size = hidden_size ##YOUR CODE HERE\n",
        "\n",
        "        # Create nn.Embedding layer with (output_size, hidden_size)\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size) ##YOUR CODE HERE\n",
        "\n",
        "        # Create nn.GRU layer with (hidden_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size) ##YOUR CODE HERE\n",
        "\n",
        "        # Create a nn.Linear layer with (hidden_size, output_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size) ##YOUR CODE HERE\n",
        "\n",
        "        # Create a nn.LogSoftmax layer with (dim=1)\n",
        "        self.softmax = nn.LogSoftmax(dim=1) ##YOUR CODE HERE\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        # Run the input through the embedding layer\n",
        "        input = self.embedding(input) ##YOUR CODE HERE\n",
        "\n",
        "        # Reshape the input with (1, 1, -1)\n",
        "        input = input.reshape(1, 1, -1) ##YOUR CODE HERE\n",
        "\n",
        "        # Use relu activation \n",
        "        input = F.relu(input)\n",
        "\n",
        "        # Run both the input and hidden through GRU\n",
        "        output, hidden = self.gru(input, hidden)##YOUR CODE HERE\n",
        "        \n",
        "        # Reshape the output with (1, -1)\n",
        "        output = output.reshape(1, -1) ##YOUR CODE HERE\n",
        "\n",
        "        # Run the output through the linear layer\n",
        "        output = self.out(output) ##YOUR CODE HERE\n",
        "\n",
        "        # Get softmax scores\n",
        "        output = self.softmax(output) ##YOUR CODE HERE\n",
        "\n",
        "        # Return both output and hidden\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        # Create a torch tensor of zeros of shape (1, 1, HIDDEN_SIZE)\n",
        "        return torch.zeros(1, 1, self.hidden_size).to(device) ##YOUR CODE HERE\n",
        "\n",
        "dummy_in = torch.randint(1, 10, (1,), device=device)\n",
        "dummy_decoder = DecoderRNN(HIDDEN_SIZE, 100).to(device)\n",
        "assert dummy_decoder.initHidden().shape == (1, 1, HIDDEN_SIZE)\n",
        "dummy_out, dummy_hid = dummy_decoder.forward(dummy_in, dummy_decoder.initHidden())\n",
        "assert dummy_out.shape == (1, 100)\n",
        "assert dummy_hid.shape == (1, 1, HIDDEN_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaYxxOpPzJII"
      },
      "source": [
        "Helper functions to convert the sentences into vector. Given a sentence, we convert it into a vector of word IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XWLLb5nPk2bh"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index.get(word, OOV_token) for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(input_lang, output_lang, pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ9VcIcgzStu"
      },
      "source": [
        "Implement the main training loop here. This function takes in one input tensor and one output tensor and does a forward pass, backward pass and weight updates. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_N-h0dp0k8wo"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, only_forward_pass=False):\n",
        "    # Initialize the hidden layer for encoder\n",
        "    encoder_hidden = encoder.initHidden() ##YOUR CODE HERE\n",
        "\n",
        "    # Reset gradients for both encoder_optimizer and decoder_optimizer\n",
        "    encoder_optimizer.zero_grad() ##YOUR CODE HERE\n",
        "    decoder_optimizer.zero_grad() ##YOUR CODE HERE\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        # Run each input word through the encoder\n",
        "        # You can access the current input as input_tensor[ei]\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden) ##YOUR CODE HERE\n",
        "\n",
        "    # First input to the decoder\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    # Assign the last encoder_hidden to decoder_hidden\n",
        "    decoder_hidden = encoder_hidden ##YOUR CODE HERE\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            # Run decoder by providing decoder_input and decoder_hidden as input\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden) ##YOUR CODE HERE\n",
        "\n",
        "            # Calculate loss\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            # Run decoder by providing decoder_input and decoder_hidden as input\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden) ##YOUR CODE HERE\n",
        "\n",
        "            # Take the top output of current timestep of decoder. This will be input to next timestep\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    if not only_forward_pass:\n",
        "        # Backprop by calling backward() function on loss\n",
        "        loss.backward() ##YOUR CODE HERE\n",
        "\n",
        "        # Update weights using step() on both encoder_optimizer and decoder_optimizer\n",
        "        encoder_optimizer.step() ##YOUR CODE HERE\n",
        "        decoder_optimizer.step() ##YOUR CODE HERE\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0xV9QrE_lGyb"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, input_lang, output_lang, pairs, learning_rate=0.01):\n",
        "    # Initialize SGD optimizers for both encoder and decoder\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    # Convert words to tensors\n",
        "    all_training_pairs = [tensorsFromPair(input_lang, output_lang, pair) for pair in pairs]\n",
        "\n",
        "    # Create training and valid datasets\n",
        "    random.shuffle(all_training_pairs)\n",
        "    valid_pairs = all_training_pairs[:500]\n",
        "    training_pairs = all_training_pairs[500:]\n",
        "    \n",
        "    # We will be using NLLLoss as criterion\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    epoch_train_losses = []\n",
        "    epoch_valid_losses = []\n",
        "\n",
        "    # In each epoch, we go through all training examples\n",
        "    for iter in range(1, n_iters + 1):\n",
        "\n",
        "        # Train\n",
        "        train_loss = 0.0\n",
        "        for training_pair in training_pairs:\n",
        "            input_tensor = training_pair[0]\n",
        "            target_tensor = training_pair[1]\n",
        "\n",
        "            loss = train(input_tensor, target_tensor, encoder,\n",
        "                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "            train_loss += loss\n",
        "\n",
        "        # Validate\n",
        "        valid_loss = 0.0\n",
        "        for val_pair in valid_pairs:\n",
        "            input_tensor = val_pair[0]\n",
        "            output_tensor = val_pair[1]\n",
        "            loss = train(input_tensor, target_tensor, encoder,\n",
        "                      decoder, encoder_optimizer, decoder_optimizer, criterion, only_forward_pass=True)\n",
        "            valid_loss += loss\n",
        "\n",
        "        avg_train_loss = train_loss / len(training_pairs)\n",
        "        avg_valid_loss = valid_loss / len(valid_pairs)\n",
        "\n",
        "        print(\"Epoch: {}/{}. Avg Train Loss: {}. Avg Valid Loss: {}\".format(iter, n_iters, avg_train_loss, avg_valid_loss))\n",
        "\n",
        "        epoch_train_losses.append(avg_train_loss)\n",
        "        epoch_valid_losses.append(avg_valid_loss)\n",
        "\n",
        "    return epoch_train_losses, epoch_valid_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLCVURlPzlUb"
      },
      "source": [
        "Train the model. What do you notice about the training and validation losses?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3580qu0lQT0",
        "outputId": "82e9959f-9499-406a-fdb9-46401dd139c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/30. Avg Train Loss: 4.831410517692475. Avg Valid Loss: 6.3342067764827155\n",
            "Epoch: 2/30. Avg Train Loss: 4.650406332947768. Avg Valid Loss: 6.455785152162827\n",
            "Epoch: 3/30. Avg Train Loss: 4.372085453710938. Avg Valid Loss: 6.369513886860436\n",
            "Epoch: 4/30. Avg Train Loss: 4.092211140243563. Avg Valid Loss: 6.523397608348303\n",
            "Epoch: 5/30. Avg Train Loss: 3.7313843630135963. Avg Valid Loss: 6.43744073104859\n",
            "Epoch: 6/30. Avg Train Loss: 3.3605752744089115. Avg Valid Loss: 6.799948815482011\n",
            "Epoch: 7/30. Avg Train Loss: 2.984694649957782. Avg Valid Loss: 6.8954312891279015\n",
            "Epoch: 8/30. Avg Train Loss: 2.60258093808855. Avg Valid Loss: 7.055781778608049\n",
            "Epoch: 9/30. Avg Train Loss: 2.260755669181207. Avg Valid Loss: 7.448570461000716\n",
            "Epoch: 10/30. Avg Train Loss: 1.9315695021810255. Avg Valid Loss: 7.369271601813181\n",
            "Epoch: 11/30. Avg Train Loss: 1.6231966273996261. Avg Valid Loss: 7.584133278982983\n",
            "Epoch: 12/30. Avg Train Loss: 1.3372506668579378. Avg Valid Loss: 7.909489355904713\n",
            "Epoch: 13/30. Avg Train Loss: 1.0977082738406407. Avg Valid Loss: 7.715901473726534\n",
            "Epoch: 14/30. Avg Train Loss: 0.9042120544446549. Avg Valid Loss: 8.092597069604048\n",
            "Epoch: 15/30. Avg Train Loss: 0.7222454955034373. Avg Valid Loss: 8.44222922842844\n",
            "Epoch: 16/30. Avg Train Loss: 0.5908843127923851. Avg Valid Loss: 8.365502073015483\n",
            "Epoch: 17/30. Avg Train Loss: 0.48349448259667355. Avg Valid Loss: 8.608939359937397\n",
            "Epoch: 18/30. Avg Train Loss: 0.38912387818917676. Avg Valid Loss: 8.868233324323382\n",
            "Epoch: 19/30. Avg Train Loss: 0.29273852461369515. Avg Valid Loss: 8.953790116446354\n",
            "Epoch: 20/30. Avg Train Loss: 0.23048867468353612. Avg Valid Loss: 8.923060731070372\n",
            "Epoch: 21/30. Avg Train Loss: 0.17421828893451594. Avg Valid Loss: 9.113756032126284\n",
            "Epoch: 22/30. Avg Train Loss: 0.14851034413338637. Avg Valid Loss: 9.070571696690152\n",
            "Epoch: 23/30. Avg Train Loss: 0.13301059882041136. Avg Valid Loss: 9.230672338213237\n",
            "Epoch: 24/30. Avg Train Loss: 0.12058204456091232. Avg Valid Loss: 9.37376446996416\n",
            "Epoch: 25/30. Avg Train Loss: 0.11156110768802119. Avg Valid Loss: 9.43787038694109\n",
            "Epoch: 26/30. Avg Train Loss: 0.11099634492399828. Avg Valid Loss: 9.47166327885219\n",
            "Epoch: 27/30. Avg Train Loss: 0.10512166354788782. Avg Valid Loss: 9.474365212576734\n",
            "Epoch: 28/30. Avg Train Loss: 0.10112201741843067. Avg Valid Loss: 9.587359670911525\n",
            "Epoch: 29/30. Avg Train Loss: 0.09736204841193809. Avg Valid Loss: 9.613687145233152\n",
            "Epoch: 30/30. Avg Train Loss: 0.094631787613653. Avg Valid Loss: 9.627595013209753\n",
            "Epoch: 1/30. Avg Train Loss: 4.203884086016471. Avg Valid Loss: 3.662754496097565\n",
            "Epoch: 2/30. Avg Train Loss: 4.14658679616461. Avg Valid Loss: 3.6677830362319948\n",
            "Epoch: 3/30. Avg Train Loss: 4.004804853564395. Avg Valid Loss: 3.7081902937889097\n",
            "Epoch: 4/30. Avg Train Loss: 3.8441702062364644. Avg Valid Loss: 3.723435369491577\n",
            "Epoch: 5/30. Avg Train Loss: 3.653690859295163. Avg Valid Loss: 3.7712831325531004\n",
            "Epoch: 6/30. Avg Train Loss: 3.403578628177957. Avg Valid Loss: 3.7778868494033815\n",
            "Epoch: 7/30. Avg Train Loss: 3.1174684246172406. Avg Valid Loss: 3.797386248588562\n",
            "Epoch: 8/30. Avg Train Loss: 2.780851073337132. Avg Valid Loss: 3.8083838753700254\n",
            "Epoch: 9/30. Avg Train Loss: 2.41813006406749. Avg Valid Loss: 3.799533411026001\n",
            "Epoch: 10/30. Avg Train Loss: 2.00718723340909. Avg Valid Loss: 3.7798807845115663\n",
            "Epoch: 11/30. Avg Train Loss: 1.6165831547953458. Avg Valid Loss: 3.954356448173523\n",
            "Epoch: 12/30. Avg Train Loss: 1.2143584794040818. Avg Valid Loss: 4.029099003791809\n",
            "Epoch: 13/30. Avg Train Loss: 0.887739530052359. Avg Valid Loss: 4.162879089832306\n",
            "Epoch: 14/30. Avg Train Loss: 0.6421555285377204. Avg Valid Loss: 4.267093309879303\n",
            "Epoch: 15/30. Avg Train Loss: 0.48346071738085744. Avg Valid Loss: 4.414849092483521\n",
            "Epoch: 16/30. Avg Train Loss: 0.38489156520736034. Avg Valid Loss: 4.49424291563034\n",
            "Epoch: 17/30. Avg Train Loss: 0.3142877740644818. Avg Valid Loss: 4.517858634471893\n",
            "Epoch: 18/30. Avg Train Loss: 0.2692579004657955. Avg Valid Loss: 4.57100525522232\n",
            "Epoch: 19/30. Avg Train Loss: 0.23257657857887817. Avg Valid Loss: 4.623411049842835\n",
            "Epoch: 20/30. Avg Train Loss: 0.20724614527918944. Avg Valid Loss: 4.645910265922546\n",
            "Epoch: 21/30. Avg Train Loss: 0.18632711848615383. Avg Valid Loss: 4.685386296272278\n",
            "Epoch: 22/30. Avg Train Loss: 0.17119088891963197. Avg Valid Loss: 4.6991342267990115\n",
            "Epoch: 23/30. Avg Train Loss: 0.1562035695876936. Avg Valid Loss: 4.751686052322388\n",
            "Epoch: 24/30. Avg Train Loss: 0.14475263061521446. Avg Valid Loss: 4.761984216213226\n",
            "Epoch: 25/30. Avg Train Loss: 0.1357089353450039. Avg Valid Loss: 4.777176248550415\n",
            "Epoch: 26/30. Avg Train Loss: 0.13008162310869537. Avg Valid Loss: 4.7811194167137145\n",
            "Epoch: 27/30. Avg Train Loss: 0.12080676289342593. Avg Valid Loss: 4.807560221195221\n",
            "Epoch: 28/30. Avg Train Loss: 0.11530577336126802. Avg Valid Loss: 4.803321751594543\n",
            "Epoch: 29/30. Avg Train Loss: 0.10999791246396068. Avg Valid Loss: 4.817690126419067\n",
            "Epoch: 30/30. Avg Train Loss: 0.10512386307451564. Avg Valid Loss: 4.83495619058609\n"
          ]
        }
      ],
      "source": [
        "# ENG - HIN\n",
        "encoder_eng_hi = EncoderRNN(input_lang_train_en_hi.n_words, HIDDEN_SIZE).to(device)\n",
        "decoder_eng_hi = DecoderRNN(HIDDEN_SIZE, output_lang_train_hi.n_words).to(device)\n",
        "\n",
        "avg_train_losses_hi, avg_valid_losses_hi = trainIters(encoder_eng_hi, decoder_eng_hi, 30, input_lang_train_en_hi, output_lang_train_hi, train_pairs_hi)\n",
        "\n",
        "# ENG - ZH\n",
        "encoder_eng_zh = EncoderRNN(input_lang_train_en_zh.n_words, HIDDEN_SIZE).to(device)\n",
        "decoder_eng_zh = DecoderRNN(HIDDEN_SIZE, output_lang_train_zh.n_words).to(device)\n",
        "\n",
        "avg_train_losses_zh, avg_valid_losses_zh = trainIters(encoder_eng_zh, decoder_eng_zh, 30, input_lang_train_en_zh, output_lang_train_zh, train_pairs_zh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lmizO_aSKjDd"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/hw06_data/losses_hi.txt\", \"w\") as fp:\n",
        "    for i,j in zip(avg_train_losses_hi, avg_valid_losses_hi):\n",
        "      fp.write(\"{:.12f} {:.12f}\\n\".format(i, j))\n",
        "\n",
        "with open(\"/content/drive/MyDrive/hw06_data/losses_zh.txt\", \"w\") as fp:\n",
        "    for i,j in zip(avg_train_losses_zh, avg_valid_losses_zh):\n",
        "      fp.write(\"{:.12f} {:.12f}\\n\".format(i, j))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ehweWG2ztnl"
      },
      "source": [
        "Function to perform inference. Given an input sentence, this function returns the translated sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AX1gbuhRgC2a"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            \n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN6VGxL4z3JY"
      },
      "source": [
        "Try out a random input. \n",
        "\n",
        "1. Does the output make sense if given an input from the training set?\n",
        "2. Does the output make sense if given an arbitrary input?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tge_5xmLrSkn",
        "outputId": "09d83123-0ff5-46ae-d8b3-8972f0a49b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['हम', 'पानी', 'क', 'अदर', 'जा', 'सकत', 'ह।', '<EOS>']\n",
            "['五間新旗艦店進駐', '<EOS>']\n"
          ]
        }
      ],
      "source": [
        "print(evaluate(encoder_eng_hi, decoder_eng_hi, \"we can go into the water\", input_lang_train_en_hi, output_lang_train_hi))\n",
        "\n",
        "print(evaluate(encoder_eng_zh, decoder_eng_zh, \"Five new flagship stores opened.\", input_lang_train_en_zh, output_lang_train_zh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxzpFaKQ0EjN"
      },
      "source": [
        "Calculate CHRF score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7vE5rlDhsFx",
        "outputId": "c669abe9-4414-421c-d348-4627248859c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/text/chrf.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  total_n_grams[n] = tensor(sum(n_grams_counts[n].values()))\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/functional/text/chrf.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  for n_gram in hyp_n_grams_counts[n]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hindi CHRF Score tensor(0.8854)\n",
            "Chinese CHRF Score tensor(0.8307)\n"
          ]
        }
      ],
      "source": [
        "hyp_hi = []\n",
        "ref_hi = []\n",
        "\n",
        "for sample in train_pairs_hi:\n",
        "    x = sample[0]\n",
        "    y_true = sample[1]\n",
        "    y_pred_tokens = evaluate(encoder_eng_hi, decoder_eng_hi, x, input_lang_train_en_hi, output_lang_train_hi)\n",
        "\n",
        "    if \"<EOS>\" in y_pred_tokens:\n",
        "        y_pred_tokens.remove(\"<EOS>\")\n",
        "    y_pred = \" \".join(y_pred_tokens)\n",
        "\n",
        "    hyp_hi.append(y_pred)\n",
        "    ref_hi.append([y_true])\n",
        "\n",
        "hyp_zh = []\n",
        "ref_zh = []\n",
        "\n",
        "for sample in train_pairs_zh:\n",
        "    x = sample[0]\n",
        "    y_true = sample[1]\n",
        "    y_pred_tokens = evaluate(encoder_eng_zh, decoder_eng_zh, x, input_lang_train_en_zh, output_lang_train_zh)\n",
        "\n",
        "    if \"<EOS>\" in y_pred_tokens:\n",
        "        y_pred_tokens.remove(\"<EOS>\")\n",
        "    y_pred = \" \".join(y_pred_tokens)\n",
        "\n",
        "    hyp_zh.append(y_pred)\n",
        "    ref_zh.append([y_true])\n",
        "\n",
        "metric = torchmetrics.CHRFScore()\n",
        "print(\"Hindi CHRF Score\", metric(hyp_hi, ref_hi))\n",
        "print(\"Chinese CHRF Score\", metric(hyp_zh, ref_zh))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mYKcTsdU-2X9"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/hw06_data/predictions_hi.txt\", \"w\") as fp:\n",
        "    for i,j in zip(hyp_hi, ref_hi):\n",
        "        fp.write(\"{} {}\\n\".format(i, str(j)))\n",
        "\n",
        "with open(\"/content/drive/MyDrive/hw06_data/predictions_zh.txt\", \"w\") as fp:\n",
        "    for i,j in zip(hyp_zh, ref_zh):\n",
        "        fp.write(\"{} {}\\n\".format(i, str(j)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TjVdXSR2LwxU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('NLP')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6584a8ba916643306bb5090a7c6d906392e220f89e7f1e5ab1565c1ede3c150"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}