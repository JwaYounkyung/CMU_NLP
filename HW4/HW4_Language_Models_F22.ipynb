{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "25d624c1",
      "metadata": {
        "id": "25d624c1"
      },
      "source": [
        "# 11411/611 – NLP (S22)\n",
        "## HW3 – Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab1cb6a9",
      "metadata": {
        "id": "ab1cb6a9"
      },
      "source": [
        "**File version:** 1.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8710365b",
      "metadata": {
        "id": "8710365b"
      },
      "source": [
        "Whether it is transcribing spoken utterances as correct word sequences or generating coherent human-like text, language models are extremely useful.\n",
        "\n",
        "In this assignment, you will be building your own language model powered by n-grams."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9cda894",
      "metadata": {
        "id": "d9cda894"
      },
      "source": [
        "### There are two major components in this HW:\n",
        "#### Part 1: Programming [60 marks]\n",
        "You are required to program an n-gram language model.\n",
        "\n",
        "#### Part 2: Analyses [40 marks]\n",
        "After writing the code, you are required to answer the empirical questions in the handout"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e485bc65",
      "metadata": {
        "id": "e485bc65"
      },
      "source": [
        "### Submission Guidelines\n",
        "\n",
        "**Deadline:** February 17th, 2022 at 11:59pm EST"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f727d4",
      "metadata": {
        "id": "e9f727d4"
      },
      "source": [
        "**Programming:** \n",
        "- This notebook contains helpful test cases and additional information about the programming part of the HW. However, you are only required to submit `lm.py` and `utils.py` on Gradescope.\n",
        "- We recommended that you first code in the notebook and then copy the corresponding methods/classes to `lm.py`.\n",
        "\n",
        "**Written:**\n",
        "- Analyses questions would require you to run your code.\n",
        "- You will submit the seperate written pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f84134d",
      "metadata": {
        "id": "1f84134d"
      },
      "source": [
        "## Part 1: Language Models [60 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0b3c6b",
      "metadata": {
        "id": "4d0b3c6b"
      },
      "source": [
        "### Step 0: Importing essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "30667bf4",
      "metadata": {
        "id": "30667bf4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from itertools import product\n",
        "import math\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d5ca5b6",
      "metadata": {
        "id": "3d5ca5b6"
      },
      "source": [
        "### Step 1: Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a6eedf",
      "metadata": {
        "id": "b3a6eedf"
      },
      "source": [
        "We provide you with a few functions in `utils.py` to read and preprocess your input data. Do not edit this file!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "195db6a3",
      "metadata": {
        "id": "195db6a3"
      },
      "outputs": [],
      "source": [
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4ea47b0",
      "metadata": {
        "id": "f4ea47b0"
      },
      "source": [
        "We have performed a round of preprocessing on the datasets.\n",
        "\n",
        "- Each file contains one sentence per line.\n",
        "- All punctuation marks have been removed.\n",
        "- Each line is a sequences of tokens separated by whitespace."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbe98cc",
      "metadata": {
        "id": "5fbe98cc"
      },
      "source": [
        "#### Special Symbols ( Already defined in `utils.py` )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "9ed9e54f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ed9e54f",
        "outputId": "9c7fe1e8-ff9c-4271-e5b6-b3c345d88f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence START symbol: <s>\n",
            "Sentence END symbol: </s>\n"
          ]
        }
      ],
      "source": [
        "print(\"Sentence START symbol: {}\".format(START))\n",
        "print(\"Sentence END symbol: {}\".format(EOS))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b1f4a6f",
      "metadata": {
        "id": "6b1f4a6f"
      },
      "source": [
        "#### Reading and processing an example file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "d60ce7c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d60ce7c2",
        "outputId": "39fa4844-051b-4c6c-db28-c95cf12e628f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['We are never ever ever ever ever getting back together\\n', 'We are the ones together we are back']\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing example for bigrams (n=2)\n",
        "sample = read_file(\"data/sample.txt\")\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "4ec373cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ec373cc",
        "outputId": "6a24253f-6927-4763-8b8f-2a70faead32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['<s>', 'we', 'are', 'never', 'ever', 'ever', 'ever', 'ever', 'getting', 'back', 'together', '</s>'], ['<s>', 'we', 'are', 'the', 'ones', 'together', 'we', 'are', 'back', '</s>']]\n"
          ]
        }
      ],
      "source": [
        "# Checkout utils.py to know more about the methods\n",
        "sample = preprocess(sample, n=2)\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d264145e",
      "metadata": {
        "id": "d264145e"
      },
      "source": [
        "### Step 2: Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "1322297b",
      "metadata": {
        "id": "1322297b"
      },
      "outputs": [],
      "source": [
        "def flatten(lst):\n",
        "    \"\"\"\n",
        "    Flattens a nested list into a 1D list.\n",
        "    Args:\n",
        "        lst: Nested list (2D)\n",
        "    \n",
        "    Returns:\n",
        "        Flattened 1-D list\n",
        "    \"\"\"\n",
        "    \n",
        "    return [item for sublist in lst for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "b51edd23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51edd23",
        "outputId": "a094ac95-45b2-4ce7-abf7-184cdece681e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd']\n"
          ]
        }
      ],
      "source": [
        "print(flatten([[\"a\", \"b\", \"c\"], [\"d\"]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9165b404",
      "metadata": {
        "id": "9165b404"
      },
      "source": [
        "### Step 3: Get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4f73b0",
      "metadata": {
        "id": "5a4f73b0"
      },
      "source": [
        "### TO DO: `get_ngrams()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "138c35b6",
      "metadata": {
        "id": "138c35b6"
      },
      "outputs": [],
      "source": [
        "#######################################\n",
        "# TO-DO: get_ngrams()\n",
        "#######################################\n",
        "def get_ngrams(list_of_words, n):\n",
        "    \"\"\"\n",
        "    Returns a list of n-grams for a list of words.\n",
        "    Args\n",
        "    ----\n",
        "    list_of_words: List[str]\n",
        "        List of already preprocessed and flattened (1D) list of tokens e.g. [\"<s>\", \"hello\", \"</s>\", \"<s>\", \"bye\", \"</s>\"]\n",
        "    n: int\n",
        "        n-gram order e.g. 1, 2, 3\n",
        "    \n",
        "    Returns:\n",
        "        n_grams: List[Tuple]\n",
        "            Returns a list containing n-gram tuples\n",
        "    \"\"\"\n",
        "\n",
        "    list_zip = []\n",
        "    for i in range(len(list_of_words) - n + 1):\n",
        "        list_zip.append(tuple(list_of_words[i:i+n]))\n",
        "\n",
        "    return list_zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "5fdab35a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "5fdab35a",
        "outputId": "fb9eeae6-f228-45c1-976a-4c16b91cd301"
      },
      "outputs": [],
      "source": [
        "n_grams = get_ngrams(flatten(sample), 3)\n",
        "assert n_grams == [('<s>', 'we', 'are'), ('we', 'are', 'never'), ('are', 'never', 'ever'), ('never', 'ever', 'ever'), ('ever', 'ever', 'ever'), ('ever', 'ever', 'ever'), ('ever', 'ever', 'getting'), ('ever', 'getting', 'back'), ('getting', 'back', 'together'), ('back', 'together', '</s>'), ('together', '</s>', '<s>'), ('</s>', '<s>', 'we'), ('<s>', 'we', 'are'), ('we', 'are', 'the'), ('are', 'the', 'ones'), ('the', 'ones', 'together'), ('ones', 'together', 'we'), ('together', 'we', 'are'), ('we', 'are', 'back'), ('are', 'back', '</s>')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bbb4a88",
      "metadata": {
        "id": "7bbb4a88"
      },
      "source": [
        "### **TO DO:** Class `LanguageModel()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7f174c9",
      "metadata": {
        "id": "f7f174c9"
      },
      "source": [
        "Now, we will define our LanguageModel class.\n",
        "\n",
        "**Required parameters:**\n",
        "- self.model: `dict` of n-grams and their corresponding probabilities.\n",
        "- self.vocab: `dict` of unigram vocabulary with counts.\n",
        "- self.n: `int` value for n-gram order (e.g. 1,2,3).\n",
        "- self.train_data: `List[List]` containing preprocessed train sentences.\n",
        "- self.alpha: `float` indicates the lazy laplace smoothing parameter (Can theoritically take any non-negative real value, stick to values between 0 and 1 for now).\n",
        "\n",
        "In `lm.py`, we will be taking most of these argumemts from command line using this command:\n",
        "\n",
        "`python3 lm.py --train data/sample.txt --test data/sample.txt --n 3 --alpha 0`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "24f2ce5c",
      "metadata": {
        "id": "24f2ce5c"
      },
      "outputs": [],
      "source": [
        "#######################################\n",
        "# TO-DO: LanguageModel()\n",
        "#######################################\n",
        "class LanguageModel():\n",
        "    def __init__(self, n, train_data, alpha=1):\n",
        "        \"\"\"\n",
        "        Language model class.\n",
        "        \n",
        "        Args\n",
        "        ____\n",
        "        n: int\n",
        "            n-gram order\n",
        "        train_data: List[List]\n",
        "            already preprocessed list of sentences. e.g. [[\"<s>\", \"hello\", \"my\", \"</s>\"], [\"<s>\", \"hi\", \"there\", \"</s>\"]]\n",
        "        alpha: float\n",
        "            Smoothing parameter\n",
        "        \n",
        "        Other required parameters:\n",
        "            self.vocab: vocabulary dict with counts\n",
        "            self.model: n-gram language model, i.e., n-gram dict with probabilties\n",
        "            self.n_grams_counts: Frequency count for each of the n-grams present in the training data\n",
        "            self.prefix_counts: Frequency count of all the corresponding n-1 grams present in the training data\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.train_data = train_data\n",
        "        self.tokens = flatten(self.train_data)\n",
        "        self.n_grams_counts = None\n",
        "        self.prefix_counts = None\n",
        "        self.vocab  = Counter(self.tokens)\n",
        "        self.alpha = alpha\n",
        "        self.model = self.build()\n",
        "\n",
        "    def get_smooth_probabilites(self,n_gram):\n",
        "        \"\"\"\n",
        "        Returns the smoothed probability of a single ngram, using Laplace Smoothing. Remember to handle the special case of n=1\n",
        "        Use the class variables we defined in the build function. It is suggested to implement the build function before this one.\n",
        "        \"\"\"\n",
        "        if self.n == 1:\n",
        "            prob = (self.n_grams_counts[n_gram]+self.alpha)  /   (len(self.tokens)+self.alpha*len(self.vocab))\n",
        "        else:\n",
        "            denominator = self.prefix_counts[n_gram[:-1]]\n",
        "            prob = (self.n_grams_counts[n_gram]+self.alpha)/(denominator+self.alpha*len(self.vocab))\n",
        "        \n",
        "        return prob\n",
        "    \n",
        "    \n",
        "    #TODO:\n",
        "    def build(self):\n",
        "        \"\"\"\n",
        "        Returns a n-gram (could be a unigram) dict with n-gram tuples as keys and probabilities as values. \n",
        "        It could be a unigram model as well\n",
        "        \"\"\"\n",
        "        \n",
        "        # TODO: Get the n-grams from the training data using the previously defined methods\n",
        "        n_grams = get_ngrams(self.tokens, self.n)\n",
        "        n_1_grams = get_ngrams(self.tokens, self.n - 1)\n",
        "        # TODO: Define the class variables n_grams_counts and prefix_counts \n",
        "        self.n_grams_counts = Counter(n_grams)\n",
        "        self.prefix_counts = Counter(n_1_grams)\n",
        "\n",
        "        # TODO Get the Probabilities using the get_smooth_probabilities\n",
        "        model = {}\n",
        "        for item, count in self.n_grams_counts.items():\n",
        "            prob = self.get_smooth_probabilites(item)\n",
        "            model[item] = prob\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "909b9c4a",
      "metadata": {
        "id": "909b9c4a"
      },
      "outputs": [],
      "source": [
        "# Quick test\n",
        "test_lm = LanguageModel(n=2, train_data=sample, alpha=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "501ac225",
      "metadata": {
        "id": "501ac225"
      },
      "outputs": [],
      "source": [
        "assert test_lm.vocab == Counter({'<s>': 2,'we': 3,'are': 3,'never': 1,'ever': 4,'getting': 1,'back': 2,'together': 2,'</s>': 2,'the': 1,'ones': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "157b0749",
      "metadata": {
        "id": "157b0749"
      },
      "outputs": [],
      "source": [
        "assert test_lm.model =={('<s>', 'we'): 1.0, ('we', 'are'): 1.0, ('are', 'never'): 0.3333333333333333, ('never', 'ever'): 1.0,('ever', 'ever'): 0.75, ('ever', 'getting'): 0.25,('getting', 'back'): 1.0,('back', 'together'): 0.5,('together', '</s>'): 0.5,('</s>', '<s>'): 0.5, ('are', 'the'): 0.3333333333333333,('the', 'ones'): 1.0,('ones', 'together'): 1.0,('together', 'we'): 0.5,('are', 'back'): 0.3333333333333333, ('back', '</s>'): 0.5}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd7f21f",
      "metadata": {
        "id": "edd7f21f"
      },
      "source": [
        "### **TO DO:**  `perplexity()`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe510005",
      "metadata": {
        "id": "fe510005"
      },
      "source": [
        "Steps:\n",
        "1. First, create n-grams after flattening the data.\n",
        "2. If a matching n-gram is not found, perform Lazy Laplace Smoothing. Remember to memoize the new n-gram probabilities to speed up calculation\n",
        "3. Refer to the perplexity equation in the language model chapter of the textbook required for this course. [[Link to the chapter]](https://web.stanford.edu/~jurafsky/slp3/3.pdf)\n",
        "\n",
        "Tips:\n",
        "- Remember that product changes summation under `log`. Take log of probabilities (`math.log()`), sum them up (`sum()`) and then exponentiate it (`math.exp()`) to get back to the original scale.\n",
        "- Make sure to `flatten()` your data before creating the n_grams using `get_ngrams().`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "id": "041d12b1",
      "metadata": {
        "id": "041d12b1"
      },
      "outputs": [],
      "source": [
        "#######################################\n",
        "# TO-DO: perplexity()\n",
        "#######################################\n",
        "def perplexity(lm, test_data):\n",
        "    \"\"\"\n",
        "    Returns perplexity calculated on the test data.\n",
        "    Args\n",
        "    ----------\n",
        "    test_data: List[List] \n",
        "        Already preprocessed nested list of sentences\n",
        "        \n",
        "    lm: LanguageModel class object\n",
        "        To be used for retrieving lm.model, lm.n and lm.vocab\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Calculated perplexity value\n",
        "    \"\"\"\n",
        "    #math.exp(sum(math.log()))\n",
        "    # TODO Flatten and get the n-grams\n",
        "    n_grams = get_ngrams(flatten(test_data), lm.n)\n",
        "    \n",
        "    # TODO Calculate the Perplexity over all the test n-grams\n",
        "    probs = lm.model\n",
        "    log_sum = 0\n",
        "    for item in n_grams:\n",
        "        try:\n",
        "            if probs[item] != 0:\n",
        "                log_sum += math.log(probs[item])\n",
        "        except:\n",
        "            if lm.n == 1:\n",
        "                prob = (lm.alpha)/(len(lm.tokens)+lm.alpha*len(lm.vocab))\n",
        "            else:\n",
        "                denominator = lm.prefix_counts[item[:-1]]\n",
        "                prob = (lm.alpha)/(denominator+lm.alpha*len(lm.vocab))\n",
        "            \n",
        "            log_sum += math.log(prob)\n",
        "        \n",
        "    perplexity = math.exp(-log_sum/len(n_grams))\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "id": "2927e9aa",
      "metadata": {
        "id": "2927e9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5358609630414888\n"
          ]
        }
      ],
      "source": [
        "# Quick test\n",
        "test_lm = LanguageModel(n=2, train_data=sample, alpha=0)\n",
        "test_ppl = perplexity(test_lm, sample)\n",
        "print(test_ppl)\n",
        "assert test_ppl < 1.7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0212dc6c",
      "metadata": {
        "id": "0212dc6c"
      },
      "source": [
        "### Step 4: Bringing everything together!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35874f48",
      "metadata": {
        "id": "35874f48"
      },
      "source": [
        "**Note:** Most of these will already be defined for you in `main()` method in `lm.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "id": "fe0fcc1c",
      "metadata": {
        "id": "fe0fcc1c"
      },
      "outputs": [],
      "source": [
        "# Arguments\n",
        "\n",
        "train_path = \"data/bbc/business.txt\"\n",
        "test_path = \"data/bbc/business.txt\"\n",
        "n = 3\n",
        "min_freq = 1\n",
        "smoothing = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "id": "3c59236d",
      "metadata": {
        "id": "3c59236d"
      },
      "outputs": [],
      "source": [
        "train = read_file(train_path)\n",
        "test = read_file(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "id": "b1c4ad51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1c4ad51",
        "outputId": "a627b46a-174a-49a9-fd4b-2a6fcc9a1f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No of sentences in train file: 19990\n",
            "No of sentences in test file: 19990\n"
          ]
        }
      ],
      "source": [
        "print(\"No of sentences in train file: {}\".format(len(train)))\n",
        "print(\"No of sentences in test file: {}\".format(len(test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "id": "271bd85a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271bd85a",
        "outputId": "67b3aef3-a66d-4283-de44-27ecd8af250b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw train example: \n",
            "13bn £ 600m for the three months to December from 639m year earlier\n",
            "\n",
            "Raw test example: \n",
            "13bn £ 600m for the three months to December from 639m year earlier\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Raw train example: \\n{}\".format(train[2]))\n",
        "print(\"Raw test example: \\n{}\".format(test[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "id": "d9edfdb7",
      "metadata": {
        "id": "d9edfdb7"
      },
      "outputs": [],
      "source": [
        "# Basic preprocessing\n",
        "train = preprocess(train, n)\n",
        "test = preprocess(test, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "id": "9f0a63a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0a63a6",
        "outputId": "0a90fb91-576a-4ce3-c23c-d096fc950bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed train example: \n",
            "['<s>', '<s>', '13bn', '£', '600m', 'for', 'the', 'three', 'months', 'to', 'december', 'from', '639m', 'year', 'earlier', '</s>']\n",
            "\n",
            "Preprocessed test example: \n",
            "['<s>', '<s>', '13bn', '£', '600m', 'for', 'the', 'three', 'months', 'to', 'december', 'from', '639m', 'year', 'earlier', '</s>']\n"
          ]
        }
      ],
      "source": [
        "print(\"Preprocessed train example: \\n{}\\n\".format(train[2]))\n",
        "print(\"Preprocessed test example: \\n{}\".format(test[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "id": "4a85f6b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a85f6b6",
        "outputId": "007ca862-7690-49cd-cf12-096b04eb91bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading 3-gram model.\n",
            "Vocabulary size (unique unigrams): 11916\n",
            "Total number of unique n-grams: 141221\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading {}-gram model.\".format(n))\n",
        "lm = LanguageModel(n, train, smoothing)\n",
        "print(\"Vocabulary size (unique unigrams): {}\".format(len(lm.vocab)))\n",
        "print(\"Total number of unique n-grams: {}\".format(len(lm.model)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "id": "22f11d60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22f11d60",
        "outputId": "1de0bef0-9c03-4491-f862-3ed6e1acce05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model perplexity: 262.742\n"
          ]
        }
      ],
      "source": [
        "# Calculate perplexity\n",
        "\n",
        "ppl = perplexity(lm, test)\n",
        "print(\"Model perplexity: {:.3f}\".format(ppl))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfab26d5",
      "metadata": {
        "id": "bfab26d5"
      },
      "source": [
        "### Step 5: Experimenting with generations!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "057decc9",
      "metadata": {
        "id": "057decc9"
      },
      "source": [
        "**Note**: These methods are already written for you. Use them to solve Written questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "id": "2289b988",
      "metadata": {
        "id": "2289b988"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(11411)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "id": "ee2382a8",
      "metadata": {
        "id": "ee2382a8"
      },
      "outputs": [],
      "source": [
        "def best_candidate(lm, prev, i, without=[], mode=\"random\"):\n",
        "    \"\"\"\n",
        "    Returns the most probable word candidate after a given sentence.\n",
        "    \"\"\"\n",
        "    blacklist  = [\"<UNK>\"] + without\n",
        "    candidates = ((ngram[-1],prob) for ngram,prob in lm.model.items() if ngram[:-1]==prev)\n",
        "    candidates = filter(lambda candidate: candidate[0] not in blacklist, candidates)\n",
        "    candidates = sorted(candidates, key=lambda candidate: candidate[1], reverse=True)\n",
        "    if len(candidates) == 0:\n",
        "        return (\"</s>\", 1)\n",
        "    else:\n",
        "        if(mode==\"random\"):\n",
        "            return candidates[random.randrange(len(candidates))]\n",
        "        else:\n",
        "            return candidates[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "id": "f1c51278",
      "metadata": {
        "id": "f1c51278"
      },
      "outputs": [],
      "source": [
        "def top_k_best_candidates(lm, prev, k, without=[]):\n",
        "    \"\"\"\n",
        "    Returns the K most-probable word candidate after a given n-1 gram.\n",
        "    Args\n",
        "    ----\n",
        "    lm: LanguageModel class object\n",
        "    \n",
        "    prev: n-1 gram\n",
        "        List of tokens n\n",
        "    \"\"\"\n",
        "    blacklist  = [\"<UNK>\"] + without\n",
        "    candidates = ((ngram[-1],prob) for ngram,prob in lm.model.items() if ngram[:-1]==prev)\n",
        "    candidates = filter(lambda candidate: candidate[0] not in blacklist, candidates)\n",
        "    candidates = sorted(candidates, key=lambda candidate: candidate[1], reverse=True)\n",
        "    if len(candidates) == 0:\n",
        "        return (\"</s>\", 1)\n",
        "    else:\n",
        "        return candidates[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "id": "9fe5444d",
      "metadata": {
        "id": "9fe5444d"
      },
      "outputs": [],
      "source": [
        "def generate_sentences_from_phrase(lm, num, sent, prob, mode):\n",
        "    \"\"\"\n",
        "    Generate sentences using the trained language model.\n",
        "    \"\"\"\n",
        "    min_len=12\n",
        "    max_len=24\n",
        "    \n",
        "    for i in range(num):\n",
        "        while sent[-1] != \"</s>\":\n",
        "            prev = () if lm.n == 1 else tuple(sent[-(lm.n-1):])\n",
        "            blacklist = sent + ([\"</s>\"] if len(sent) < min_len else [])\n",
        "\n",
        "            next_token, next_prob = best_candidate(lm, prev, i, without=blacklist, mode=mode)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "            \n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(\"</s>\")\n",
        "\n",
        "        yield ' '.join(sent), -1/math.log(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "id": "45040312",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('</s>', '<s>', '<s>'), 19989),\n",
              " (('<s>', '<s>', 'the'), 3474),\n",
              " (('said', '</s>', '<s>'), 688),\n",
              " (('<s>', '<s>', 'it'), 640),\n",
              " (('1', '</s>', '<s>'), 560),\n",
              " (('<s>', '<s>', 'in'), 528),\n",
              " (('<s>', '<s>', 'but'), 516),\n",
              " (('<s>', '<s>', 'mr'), 422),\n",
              " (('<s>', '<s>', 'however'), 380),\n",
              " (('year', '</s>', '<s>'), 346),\n",
              " (('<s>', '<s>', 'a'), 336),\n",
              " (('2', '</s>', '<s>'), 322),\n",
              " (('<s>', '<s>', 'we'), 292),\n",
              " (('0', '</s>', '<s>'), 248),\n",
              " (('4', '</s>', '<s>'), 234),\n",
              " (('<s>', '<s>', 'he'), 222),\n",
              " (('the', 'world', 's'), 218),\n",
              " (('3', '</s>', '<s>'), 210),\n",
              " (('<s>', '<s>', '5'), 204),\n",
              " (('<s>', '<s>', 'this'), 196),\n",
              " (('the', 'country', 's'), 192),\n",
              " (('in', 'the', 'us'), 184),\n",
              " (('<s>', '<s>', '1'), 176),\n",
              " (('5', '</s>', '<s>'), 174),\n",
              " (('he', 'said', '</s>'), 172),\n",
              " (('<s>', '<s>', 'us'), 172),\n",
              " (('<s>', 'the', 'company'), 166),\n",
              " (('<s>', '<s>', 'analysts'), 166),\n",
              " (('2004', '</s>', '<s>'), 164),\n",
              " (('<s>', '<s>', '3'), 160),\n",
              " (('years', '</s>', '<s>'), 154),\n",
              " (('<s>', 'the', 'us'), 150),\n",
              " (('<s>', '<s>', 'i'), 148),\n",
              " (('market', '</s>', '<s>'), 148),\n",
              " (('<s>', '<s>', '5bn'), 146),\n",
              " (('<s>', '<s>', '2'), 144),\n",
              " (('economy', '</s>', '<s>'), 140),\n",
              " (('2005', '</s>', '<s>'), 138),\n",
              " (('2003', '</s>', '<s>'), 134),\n",
              " (('<s>', '<s>', 'there'), 134),\n",
              " (('<s>', '<s>', 'they'), 130),\n",
              " (('<s>', '<s>', '7'), 126),\n",
              " (('<s>', '<s>', 'on'), 122),\n",
              " (('<s>', '<s>', 'yukos'), 122),\n",
              " (('<s>', 'it', 'is'), 122),\n",
              " (('<s>', '<s>', '8'), 122),\n",
              " (('<s>', '<s>', '6'), 120),\n",
              " (('<s>', 'but', 'the'), 118),\n",
              " (('£', '1', '</s>'), 116),\n",
              " (('<s>', '<s>', 'shares'), 116),\n",
              " (('<s>', '<s>', '4'), 114),\n",
              " (('6', '</s>', '<s>'), 110),\n",
              " (('<s>', '<s>', 'and'), 110),\n",
              " (('<s>', '<s>', 'as'), 110),\n",
              " (('last', 'year', '</s>'), 110),\n",
              " (('<s>', 'the', 'firm'), 106),\n",
              " (('one', 'of', 'the'), 106),\n",
              " (('8', '</s>', '<s>'), 106),\n",
              " (('added', '</s>', '<s>'), 106),\n",
              " (('<s>', '<s>', 'china'), 104),\n",
              " (('growth', '</s>', '<s>'), 102),\n",
              " (('<s>', '<s>', 'at'), 100),\n",
              " (('the', 'end', 'of'), 100),\n",
              " (('<s>', '<s>', '4bn'), 100),\n",
              " (('according', 'to', 'the'), 100),\n",
              " (('<s>', 'in', 'the'), 98),\n",
              " (('<s>', '<s>', 'according'), 98),\n",
              " (('in', 'a', 'statement'), 98),\n",
              " (('as', 'well', 'as'), 96),\n",
              " (('<s>', 'shares', 'in'), 96),\n",
              " (('<s>', '<s>', 'last'), 96),\n",
              " (('<s>', 'according', 'to'), 96),\n",
              " (('is', 'expected', 'to'), 94),\n",
              " (('<s>', '<s>', 'if'), 94),\n",
              " (('<s>', '<s>', 'its'), 90),\n",
              " (('<s>', 'however', 'the'), 90),\n",
              " (('<s>', '<s>', 'india'), 90),\n",
              " (('deal', '</s>', '<s>'), 90),\n",
              " (('<s>', '<s>', '8bn'), 88),\n",
              " (('said', 'it', 'was'), 86),\n",
              " (('the', 'company', 's'), 86),\n",
              " (('9', '</s>', '<s>'), 84),\n",
              " (('<s>', '<s>', 'that'), 84),\n",
              " (('said', 'in', 'a'), 84),\n",
              " (('7', '</s>', '<s>'), 82),\n",
              " (('<s>', '<s>', '3bn'), 80),\n",
              " (('<s>', 'the', 'government'), 80),\n",
              " (('<s>', '<s>', 'some'), 80),\n",
              " (('<s>', '<s>', 'for'), 78),\n",
              " (('<s>', 'we', 'are'), 78),\n",
              " (('of', 'the', 'world'), 78),\n",
              " (('<s>', '<s>', '9'), 78),\n",
              " (('the', 'bank', 'of'), 78),\n",
              " (('as', 'part', 'of'), 76),\n",
              " (('said', 'that', 'the'), 76),\n",
              " (('<s>', '<s>', '6bn'), 76),\n",
              " (('in', '2003', '</s>'), 76),\n",
              " (('a', 'number', 'of'), 74),\n",
              " (('<s>', '<s>', 'despite'), 74),\n",
              " (('of', 'the', 'us'), 74),\n",
              " (('bank', 'of', 'england'), 74),\n",
              " (('10', '</s>', '<s>'), 72),\n",
              " (('in', 'the', 'uk'), 72),\n",
              " (('in', '2004', '</s>'), 72),\n",
              " (('month', '</s>', '<s>'), 72),\n",
              " (('<s>', 'it', 'also'), 70),\n",
              " (('<s>', '<s>', '7bn'), 70),\n",
              " (('us', '</s>', '<s>'), 70),\n",
              " (('as', 'a', 'result'), 70),\n",
              " (('statement', '</s>', '<s>'), 70),\n",
              " (('bid', '</s>', '<s>'), 70),\n",
              " (('months', '</s>', '<s>'), 68),\n",
              " (('the', 'firm', 's'), 68),\n",
              " (('the', 'government', 's'), 66),\n",
              " (('this', 'year', '</s>'), 66),\n",
              " (('<s>', '<s>', 'meanwhile'), 66),\n",
              " (('<s>', '<s>', 'while'), 66),\n",
              " (('<s>', '<s>', '1bn'), 64),\n",
              " (('january', '</s>', '<s>'), 64),\n",
              " (('the', 'us', '</s>'), 64),\n",
              " (('said', 'it', 'would'), 64),\n",
              " (('<s>', 'the', 'bank'), 64),\n",
              " (('<s>', '<s>', '2bn'), 62),\n",
              " (('in', '2005', '</s>'), 62),\n",
              " (('<s>', '<s>', 'under'), 62),\n",
              " (('costs', '</s>', '<s>'), 62),\n",
              " (('the', 'cost', 'of'), 62),\n",
              " (('the', 'sale', 'of'), 60),\n",
              " (('in', 'new', 'york'), 60),\n",
              " (('has', 'said', 'it'), 60),\n",
              " (('the', 'us', 'economy'), 60),\n",
              " (('<s>', '<s>', 'with'), 60),\n",
              " (('over', 'the', 'next'), 60),\n",
              " (('<s>', '<s>', 'uk'), 60),\n",
              " (('said', 'it', 'had'), 58),\n",
              " (('business', '</s>', '<s>'), 58),\n",
              " (('in', 'the', 'past'), 58),\n",
              " (('<s>', 'this', 'is'), 58),\n",
              " (('the', 'number', 'of'), 58),\n",
              " (('a', 'statement', '</s>'), 58),\n",
              " (('world', 's', 'biggest'), 58),\n",
              " (('for', 'the', 'first'), 58),\n",
              " (('<s>', 'in', 'a'), 58),\n",
              " (('the', 'value', 'of'), 56),\n",
              " (('jobs', '</s>', '<s>'), 56),\n",
              " (('<s>', 'analysts', 'said'), 56),\n",
              " (('to', '2', '</s>'), 56),\n",
              " (('the', 'uk', 's'), 56),\n",
              " (('in', 'the', 'last'), 56),\n",
              " (('the', 'fourth', 'quarter'), 54),\n",
              " (('<s>', 'it', 'has'), 54),\n",
              " (('<s>', '1', 'in'), 54),\n",
              " (('<s>', 'it', 's'), 54),\n",
              " (('is', 'likely', 'to'), 54),\n",
              " (('firm', '</s>', '<s>'), 54),\n",
              " (('<s>', '<s>', 'deutsche'), 54),\n",
              " (('earlier', '</s>', '<s>'), 52),\n",
              " (('sales', '</s>', '<s>'), 52),\n",
              " (('the', 'company', 'said'), 52),\n",
              " (('a', 'year', 'earlier'), 52),\n",
              " (('euros', '</s>', '<s>'), 52),\n",
              " (('<s>', '<s>', 'many'), 52),\n",
              " (('prices', '</s>', '<s>'), 52),\n",
              " (('<s>', '<s>', 'one'), 52),\n",
              " (('<s>', '<s>', 'sales'), 52),\n",
              " (('the', 'first', 'time'), 52),\n",
              " (('<s>', 'at', 'the'), 52),\n",
              " (('shares', '</s>', '<s>'), 52),\n",
              " (('part', 'of', 'the'), 50),\n",
              " (('as', 'much', 'as'), 50),\n",
              " (('december', '</s>', '<s>'), 50),\n",
              " (('he', 'added', '</s>'), 50),\n",
              " (('are', 'likely', 'to'), 50),\n",
              " (('2006', '</s>', '<s>'), 50),\n",
              " (('<s>', '<s>', 'although'), 50),\n",
              " (('<s>', '<s>', 'these'), 50),\n",
              " (('year', 'earlier', '</s>'), 48),\n",
              " (('is', 'set', 'to'), 48),\n",
              " (('the', 'united', 'states'), 48),\n",
              " (('<s>', '<s>', 'japan'), 48),\n",
              " (('<s>', 'he', 'said'), 48),\n",
              " (('are', 'expected', 'to'), 48),\n",
              " (('company', '</s>', '<s>'), 48),\n",
              " (('<s>', '<s>', 'both'), 48),\n",
              " (('<s>', 'china', 's'), 46),\n",
              " (('some', 'of', 'the'), 46),\n",
              " (('<s>', '<s>', 'since'), 46),\n",
              " (('<s>', 'the', 'economy'), 46),\n",
              " (('says', '</s>', '<s>'), 46),\n",
              " (('over', 'the', 'past'), 46),\n",
              " (('ago', '</s>', '<s>'), 46),\n",
              " (('in', 'the', 'first'), 46),\n",
              " (('<s>', 'the', 'move'), 46),\n",
              " (('be', 'able', 'to'), 46),\n",
              " (('the', 'us', 'dollar'), 46),\n",
              " (('of', 'the', 'year'), 46),\n",
              " (('said', 'that', 'it'), 46),\n",
              " (('to', '1', '</s>'), 44),\n",
              " (('£', '2', '</s>'), 44),\n",
              " (('the', 'financial', 'times'), 44),\n",
              " (('<s>', '2', 'in'), 44),\n",
              " (('12', '</s>', '<s>'), 44),\n",
              " (('<s>', 'it', 'was'), 44),\n",
              " (('the', 'russian', 'government'), 44),\n",
              " (('<s>', '<s>', 'gm'), 44),\n",
              " (('of', 'the', 'country'), 44),\n",
              " (('london', 'stock', 'exchange'), 44),\n",
              " (('<s>', 'the', 'uk'), 44),\n",
              " (('months', 'of', '2004'), 44),\n",
              " (('earlier', 'this', 'month'), 44),\n",
              " (('the', 'previous', 'year'), 44),\n",
              " (('<s>', '<s>', 'other'), 44),\n",
              " (('the', 'housing', 'market'), 44),\n",
              " (('in', 'the', 'world'), 44),\n",
              " (('sector', '</s>', '<s>'), 44),\n",
              " (('a', 'lot', 'of'), 44),\n",
              " (('<s>', '<s>', '9bn'), 42),\n",
              " (('in', 'the', 'fourth'), 42),\n",
              " (('<s>', 'the', 'dollar'), 42),\n",
              " (('in', 'recent', 'months'), 42),\n",
              " (('rates', '</s>', '<s>'), 42),\n",
              " (('will', 'have', 'to'), 42),\n",
              " (('case', '</s>', '<s>'), 42),\n",
              " (('a', 'us', 'court'), 42),\n",
              " (('part', 'of', 'a'), 42),\n",
              " (('firms', '</s>', '<s>'), 42),\n",
              " (('group', '</s>', '<s>'), 42),\n",
              " (('<s>', 'the', 'deal'), 42),\n",
              " (('markets', '</s>', '<s>'), 42),\n",
              " (('<s>', 'there', 'are'), 42),\n",
              " (('reported', '</s>', '<s>'), 42),\n",
              " (('<s>', '<s>', '5m'), 42),\n",
              " (('countries', '</s>', '<s>'), 42),\n",
              " (('told', 'the', 'bbc'), 42),\n",
              " (('the', 'london', 'stock'), 42),\n",
              " (('of', '2004', '</s>'), 42),\n",
              " (('that', 'it', 'was'), 42),\n",
              " (('<s>', '<s>', 'by'), 42),\n",
              " (('analysts', 'said', '</s>'), 42),\n",
              " (('that', 'it', 'is'), 42),\n",
              " (('the', 'three', 'months'), 40),\n",
              " (('<s>', '<s>', 'our'), 40),\n",
              " (('against', 'the', 'euro'), 40),\n",
              " (('for', 'the', 'year'), 40),\n",
              " (('the', 'third', 'quarter'), 40),\n",
              " (('week', '</s>', '<s>'), 40),\n",
              " (('likely', 'to', 'be'), 40),\n",
              " (('bank', '</s>', '<s>'), 40),\n",
              " (('reuters', '</s>', '<s>'), 40),\n",
              " (('the', 'price', 'of'), 40),\n",
              " (('the', 'start', 'of'), 40),\n",
              " (('<s>', 'we', 'have'), 40),\n",
              " (('a', 'year', 'ago'), 40),\n",
              " (('the', 'european', 'union'), 40),\n",
              " (('<s>', '<s>', 'earlier'), 40),\n",
              " (('three', 'months', 'of'), 40),\n",
              " (('in', 'the', 'second'), 40),\n",
              " (('of', 'the', 'economy'), 40),\n",
              " (('offer', '</s>', '<s>'), 40),\n",
              " (('an', 'analyst', 'at'), 40),\n",
              " (('said', 'it', 'will'), 40),\n",
              " (('three', 'months', 'to'), 38),\n",
              " (('sale', '</s>', '<s>'), 38),\n",
              " (('profits', '</s>', '<s>'), 38),\n",
              " (('the', 'year', 'to'), 38),\n",
              " (('<s>', 'last', 'year'), 38),\n",
              " (('value', 'of', 'the'), 38),\n",
              " (('in', 'the', 'year'), 38),\n",
              " (('a', 'series', 'of'), 38),\n",
              " (('<s>', '<s>', 'growth'), 38),\n",
              " (('the', 'same', 'period'), 38),\n",
              " (('<s>', 'india', 's'), 38),\n",
              " (('a', 'spokesman', 'for'), 38),\n",
              " (('2002', '</s>', '<s>'), 38),\n",
              " (('told', 'reuters', '</s>'), 38),\n",
              " (('in', 'the', 'country'), 38),\n",
              " (('of', 'more', 'than'), 38),\n",
              " (('securities', 'and', 'exchange'), 38),\n",
              " (('and', 'exchange', 'commission'), 38),\n",
              " (('deficit', '</s>', '<s>'), 38),\n",
              " (('an', 'effort', 'to'), 38),\n",
              " (('the', 'year', '</s>'), 38),\n",
              " (('by', 'the', 'end'), 38),\n",
              " (('<s>', '<s>', 'investors'), 38),\n",
              " (('<s>', '<s>', 'more'), 38),\n",
              " (('mr', 'glazer', 's'), 38),\n",
              " (('<s>', 'i', 'think'), 36),\n",
              " (('dollar', '</s>', '<s>'), 36),\n",
              " (('a', 'fall', 'in'), 36),\n",
              " (('2001', '</s>', '<s>'), 36),\n",
              " (('<s>', 'as', 'a'), 36),\n",
              " (('<s>', '5', 'in'), 36),\n",
              " (('14', '</s>', '<s>'), 36),\n",
              " (('quarter', 'of', '2004'), 36),\n",
              " (('in', 'order', 'to'), 36),\n",
              " (('<s>', 'the', 'european'), 36),\n",
              " (('report', '</s>', '<s>'), 36),\n",
              " (('to', '4', '</s>'), 36),\n",
              " (('the', 'fact', 'that'), 36),\n",
              " (('5bn', '</s>', '<s>'), 36),\n",
              " (('demand', '</s>', '<s>'), 36),\n",
              " (('expected', 'to', 'be'), 36),\n",
              " (('future', '</s>', '<s>'), 36),\n",
              " (('the', 'market', '</s>'), 36),\n",
              " (('<s>', '<s>', '75'), 36),\n",
              " (('<s>', 'mr', 'ebbers'), 36),\n",
              " (('<s>', '<s>', '25'), 36),\n",
              " (('to', 'the', 'us'), 36),\n",
              " (('<s>', '<s>', 'standard'), 36),\n",
              " (('is', 'one', 'of'), 36),\n",
              " (('<s>', '<s>', 'an'), 36),\n",
              " (('yukos', '</s>', '<s>'), 34),\n",
              " (('reuters', 'news', 'agency'), 34),\n",
              " (('in', 'january', '</s>'), 34),\n",
              " (('last', 'year', 's'), 34),\n",
              " (('<s>', '<s>', 'president'), 34),\n",
              " (('£', '3', '</s>'), 34),\n",
              " (('budget', '</s>', '<s>'), 34),\n",
              " (('<s>', '<s>', 'when'), 34),\n",
              " (('control', '</s>', '<s>'), 34),\n",
              " (('a', 'year', '</s>'), 34),\n",
              " (('more', 'than', 'a'), 34),\n",
              " (('15', '</s>', '<s>'), 34),\n",
              " (('<s>', '<s>', 'overall'), 34),\n",
              " (('september', '</s>', '<s>'), 34),\n",
              " (('<s>', '<s>', 'german'), 34),\n",
              " (('16', '</s>', '<s>'), 34),\n",
              " (('<s>', '<s>', '0'), 34),\n",
              " (('<s>', '3', 'in'), 34),\n",
              " (('in', 'line', 'with'), 34),\n",
              " (('fraud', '</s>', '<s>'), 34),\n",
              " (('in', 'an', 'effort'), 34),\n",
              " (('<s>', '<s>', 'oil'), 34),\n",
              " (('the', 'amount', 'of'), 34),\n",
              " (('<s>', 'there', 'is'), 34),\n",
              " (('17', '</s>', '<s>'), 34),\n",
              " (('bankruptcy', 'protection', 'in'), 32),\n",
              " (('s', 'chief', 'executive'), 32),\n",
              " (('in', 'the', 'third'), 32),\n",
              " (('analysts', 'said', 'the'), 32),\n",
              " (('the', 'economy', 'is'), 32),\n",
              " (('gross', 'domestic', 'product'), 32),\n",
              " (('many', 'of', 'the'), 32),\n",
              " (('to', 'be', 'a'), 32),\n",
              " (('<s>', 'the', 'two'), 32),\n",
              " (('europe', '</s>', '<s>'), 32),\n",
              " (('it', 's', 'a'), 32),\n",
              " (('out', '</s>', '<s>'), 32),\n",
              " (('high', '</s>', '<s>'), 32),\n",
              " (('world', '</s>', '<s>'), 32),\n",
              " (('<s>', 'despite', 'the'), 32),\n",
              " (('world', 's', 'largest'), 32),\n",
              " (('<s>', 'if', 'the'), 32),\n",
              " (('in', 'recent', 'years'), 32),\n",
              " (('<s>', 'the', 'sec'), 32),\n",
              " (('<s>', '<s>', 'his'), 32),\n",
              " (('companies', '</s>', '<s>'), 32),\n",
              " (('<s>', 'it', 'said'), 32),\n",
              " (('george', 'w', 'bush'), 32),\n",
              " (('by', '0', '</s>'), 32),\n",
              " (('a', 'slowdown', 'in'), 32),\n",
              " (('industry', '</s>', '<s>'), 32),\n",
              " (('<s>', '<s>', 'fiat'), 32),\n",
              " (('<s>', '<s>', 'consumer'), 32),\n",
              " (('<s>', 'last', 'week'), 32),\n",
              " (('28', '</s>', '<s>'), 32),\n",
              " (('the', 'firm', 'said'), 32),\n",
              " (('by', '1', '</s>'), 32),\n",
              " (('<s>', '<s>', 'boeing'), 32),\n",
              " (('november', '</s>', '<s>'), 32),\n",
              " (('it', '</s>', '<s>'), 30),\n",
              " (('thursday', '</s>', '<s>'), 30),\n",
              " (('<s>', '<s>', 'to'), 30),\n",
              " (('two', 'thirds', 'of'), 30),\n",
              " (('in', 'the', 'three'), 30),\n",
              " (('quarter', '</s>', '<s>'), 30),\n",
              " (('to', '5', '</s>'), 30),\n",
              " (('he', 'said', 'the'), 30),\n",
              " (('exports', '</s>', '<s>'), 30),\n",
              " (('<s>', '<s>', 'during'), 30),\n",
              " (('30', '</s>', '<s>'), 30),\n",
              " (('<s>', 'the', 'new'), 30),\n",
              " (('<s>', '5bn', '</s>'), 30),\n",
              " (('<s>', 'the', 'world'), 30),\n",
              " (('day', '</s>', '<s>'), 30),\n",
              " (('<s>', '6', 'in'), 30),\n",
              " (('october', '</s>', '<s>'), 30),\n",
              " (('that', 'it', 'would'), 30),\n",
              " (('there', 'is', 'no'), 30),\n",
              " (('such', 'as', 'the'), 30),\n",
              " (('the', 'strength', 'of'), 30),\n",
              " (('shareholders', '</s>', '<s>'), 30),\n",
              " (('has', 'agreed', 'to'), 30),\n",
              " (('said', 'it', 'is'), 30),\n",
              " (('a', 'result', 'of'), 30),\n",
              " (('trade', '</s>', '<s>'), 30),\n",
              " (('for', 'the', 'us'), 30),\n",
              " (('<s>', 'earlier', 'this'), 30),\n",
              " (('agency', '</s>', '<s>'), 30),\n",
              " (('because', 'of', 'the'), 30),\n",
              " (('the', 'stock', 'market'), 30),\n",
              " (('<s>', 'under', 'the'), 30),\n",
              " (('economic', 'growth', '</s>'), 30),\n",
              " (('also', 'said', 'that'), 30),\n",
              " (('the', 'company', '</s>'), 30),\n",
              " (('according', 'to', 'a'), 30),\n",
              " (('<s>', '<s>', 'france'), 30),\n",
              " (('end', 'of', 'the'), 30),\n",
              " (('<s>', 'more', 'than'), 30),\n",
              " (('<s>', '<s>', 'most'), 30),\n",
              " (('exchange', '</s>', '<s>'), 30),\n",
              " (('<s>', 'mr', 'glazer'), 30),\n",
              " (('11', '</s>', '<s>'), 28),\n",
              " (('the', 'federal', 'reserve'), 28),\n",
              " (('on', 'thursday', '</s>'), 28),\n",
              " (('the', 'company', 'has'), 28),\n",
              " (('filed', 'for', 'bankruptcy'), 28),\n",
              " (('rosneft', '</s>', '<s>'), 28),\n",
              " (('the', 'political', 'ambitions'), 28),\n",
              " (('political', 'ambitions', 'of'), 28),\n",
              " (('<s>', 'however', 'it'), 28),\n",
              " (('to', 'comment', 'on'), 28),\n",
              " (('£', '5', '</s>'), 28),\n",
              " (('recovery', '</s>', '<s>'), 28),\n",
              " (('court', '</s>', '<s>'), 28),\n",
              " (('<s>', '<s>', 'among'), 28),\n",
              " (('tuesday', '</s>', '<s>'), 28),\n",
              " (('rise', '</s>', '<s>'), 28),\n",
              " (('the', 'government', 'to'), 28),\n",
              " (('staff', '</s>', '<s>'), 28),\n",
              " (('this', 'is', 'a'), 28),\n",
              " (('<s>', '<s>', 'parmalat'), 28),\n",
              " (('chief', 'financial', 'officer'), 28),\n",
              " (('growth', 'in', 'the'), 28),\n",
              " (('<s>', '1', '</s>'), 28),\n",
              " (('at', 'the', 'end'), 28),\n",
              " (('country', '</s>', '<s>'), 28),\n",
              " (('government', '</s>', '<s>'), 28),\n",
              " (('has', 'said', '</s>'), 28),\n",
              " (('<s>', 'but', 'it'), 28),\n",
              " (('time', '</s>', '<s>'), 28),\n",
              " (('the', 'securities', 'and'), 28),\n",
              " (('the', 'bank', 's'), 28),\n",
              " (('it', 'said', '</s>'), 28),\n",
              " (('as', 'saying', '</s>'), 28),\n",
              " (('saying', '</s>', '<s>'), 28),\n",
              " (('investment', '</s>', '<s>'), 28),\n",
              " (('of', 'the', 'uk'), 28),\n",
              " (('agreed', 'to', 'pay'), 28),\n",
              " (('<s>', 'the', 'country'), 28),\n",
              " (('at', '4', '</s>'), 28),\n",
              " (('slowdown', 'in', 'the'), 28),\n",
              " (('it', 'would', 'be'), 28),\n",
              " (('<s>', '<s>', 'another'), 28),\n",
              " (('pleaded', 'guilty', 'to'), 28),\n",
              " (('work', '</s>', '<s>'), 28),\n",
              " (('<s>', '<s>', 'turkey'), 28),\n",
              " (('<s>', '<s>', 'no'), 28),\n",
              " (('in', 'the', 'market'), 28),\n",
              " (('international', 'monetary', 'fund'), 28),\n",
              " (('the', 'group', 's'), 28),\n",
              " (('on', 'wednesday', '</s>'), 28),\n",
              " (('wednesday', '</s>', '<s>'), 28),\n",
              " (('<s>', 'deutsche', 'boerse'), 28),\n",
              " (('<s>', '<s>', 'cairn'), 28),\n",
              " (('lse', '</s>', '<s>'), 28),\n",
              " (('<s>', '<s>', 'so'), 28),\n",
              " (('and', 'chief', 'executive'), 26),\n",
              " (('ahead', 'of', 'the'), 26),\n",
              " (('the', 'face', 'of'), 26),\n",
              " (('in', 'terms', 'of'), 26),\n",
              " (('show', '</s>', '<s>'), 26),\n",
              " (('the', 'unemployment', 'rate'), 26),\n",
              " (('also', 'said', 'it'), 26),\n",
              " (('chief', 'economist', 'at'), 26),\n",
              " (('<s>', '<s>', 'about'), 26),\n",
              " (('<s>', '<s>', 'prosecutors'), 26),\n",
              " (('products', '</s>', '<s>'), 26),\n",
              " (('the', 'bbc', 's'), 26),\n",
              " (('that', 'the', 'company'), 26),\n",
              " (('<s>', '<s>', 'air'), 26),\n",
              " (('<s>', '<s>', 'new'), 26),\n",
              " (('the', 'government', 'has'), 26),\n",
              " (('<s>', '7', 'in'), 26),\n",
              " (('accounts', '</s>', '<s>'), 26),\n",
              " (('it', 'is', 'a'), 26),\n",
              " (('to', 'a', 'record'), 26),\n",
              " (('customers', '</s>', '<s>'), 26),\n",
              " (('the', 'world', '</s>'), 26),\n",
              " (('on', 'friday', '</s>'), 26),\n",
              " (('friday', '</s>', '<s>'), 26),\n",
              " (('high', 'oil', 'prices'), 26),\n",
              " (('18', '</s>', '<s>'), 26),\n",
              " (('the', 'dollar', 's'), 26),\n",
              " (('is', 'due', 'to'), 26),\n",
              " (('<s>', '<s>', 'news'), 26),\n",
              " (('that', 'it', 'had'), 26),\n",
              " (('<s>', '8', 'in'), 26),\n",
              " (('the', 'next', 'few'), 26),\n",
              " (('of', '2005', '</s>'), 26),\n",
              " (('news', '</s>', '<s>'), 26),\n",
              " (('£', '4', '</s>'), 26),\n",
              " (('strength', 'of', 'the'), 26),\n",
              " (('<s>', '<s>', 'now'), 26),\n",
              " (('debt', '</s>', '<s>'), 26),\n",
              " (('china', '</s>', '<s>'), 26),\n",
              " (('the', 'us', 'and'), 26),\n",
              " (('the', 'last', 'three'), 26),\n",
              " (('last', 'three', 'months'), 26),\n",
              " (('news', 'agency', '</s>'), 26),\n",
              " (('five', 'years', '</s>'), 26),\n",
              " (('board', '</s>', '<s>'), 26),\n",
              " (('<s>', '<s>', 'south'), 26),\n",
              " (('south', 'korea', 's'), 26),\n",
              " (('of', 'the', 'company'), 26),\n",
              " (('last', 'month', '</s>'), 26),\n",
              " (('<s>', 'the', 'figures'), 26),\n",
              " (('would', 'continue', 'to'), 26),\n",
              " (('the', 'first', 'half'), 26),\n",
              " (('first', 'half', 'of'), 26),\n",
              " (('the', 'world', 'trade'), 26),\n",
              " (('the', 'firm', 'has'), 26),\n",
              " (('<s>', '<s>', 'even'), 26),\n",
              " (('oil', 'and', 'gas'), 26),\n",
              " (('the', 'international', 'monetary'), 26),\n",
              " (('at', 'the', 'time'), 26),\n",
              " (('the', 'size', 'of'), 26),\n",
              " (('to', 'pay', 'a'), 26),\n",
              " (('are', 'going', 'to'), 26),\n",
              " (('by', 'more', 'than'), 26),\n",
              " (('to', 'buy', 'the'), 26),\n",
              " (('it', 'is', 'not'), 26),\n",
              " (('to', 'the', 'financial'), 26),\n",
              " (('expectations', '</s>', '<s>'), 24),\n",
              " (('of', '3', '</s>'), 24),\n",
              " (('<s>', 'it', 'will'), 24),\n",
              " (('current', 'account', 'deficit'), 24),\n",
              " (('the', 'case', '</s>'), 24),\n",
              " (('a', 'rise', 'in'), 24),\n",
              " (('in', 'the', 'face'), 24),\n",
              " (('just', '0', '</s>'), 24),\n",
              " (('rules', '</s>', '<s>'), 24),\n",
              " (('<s>', '5', '</s>'), 24),\n",
              " (('on', 'tuesday', '</s>'), 24),\n",
              " (('it', 'said', 'it'), 24),\n",
              " (('airlines', '</s>', '<s>'), 24),\n",
              " (('the', 'european', 'commission'), 24),\n",
              " (('lead', 'to', 'a'), 24),\n",
              " (('there', 'is', 'a'), 24),\n",
              " (('out', 'of', 'the'), 24),\n",
              " (('<s>', 'a', 'spokesman'), 24),\n",
              " (('the', 'government', 'is'), 24),\n",
              " (('last', 'year', 'and'), 24),\n",
              " (('of', '1', '</s>'), 24),\n",
              " (('<s>', '<s>', 'russia'), 24),\n",
              " (('the', 'first', 'quarter'), 24),\n",
              " (('<s>', '4', 'in'), 24),\n",
              " (('low', '</s>', '<s>'), 24),\n",
              " (('are', 'set', 'to'), 24),\n",
              " (('s', 'second', 'largest'), 24),\n",
              " (('<s>', 'he', 'added'), 24),\n",
              " (('april', '</s>', '<s>'), 24),\n",
              " (('the', 'future', 'of'), 24),\n",
              " (('<s>', '<s>', 'chief'), 24),\n",
              " (('<s>', 'chief', 'executive'), 24),\n",
              " (('and', 'it', 'is'), 24),\n",
              " (('<s>', '<s>', '4m'), 24),\n",
              " (('expected', '</s>', '<s>'), 24),\n",
              " (('president', 'george', 'w'), 24),\n",
              " (('decade', '</s>', '<s>'), 24),\n",
              " (('on', 'the', 'market'), 24),\n",
              " (('of', 'the', 'group'), 24),\n",
              " (('<s>', '<s>', 'bmw'), 24),\n",
              " (('at', 'the', 'same'), 24),\n",
              " (('the', 'same', 'time'), 24),\n",
              " (('asia', '</s>', '<s>'), 24),\n",
              " (('club', '</s>', '<s>'), 24),\n",
              " (('<s>', '<s>', 'worldcom'), 24),\n",
              " (('of', 'the', 'firm'), 24),\n",
              " (('an', 'increase', 'in'), 24),\n",
              " (('the', 'second', 'half'), 24),\n",
              " (('will', 'not', 'be'), 24),\n",
              " (('the', 'hands', 'of'), 24),\n",
              " (('of', 'up', 'to'), 24),\n",
              " (('<s>', '<s>', 'economic'), 24),\n",
              " (('the', 'two', 'countries'), 24),\n",
              " (('<s>', '<s>', 'russian'), 24),\n",
              " (('<s>', 'but', 'he'), 24),\n",
              " (('to', 'cut', 'costs'), 24),\n",
              " (('<s>', 'on', 'the'), 24),\n",
              " (('annual', 'rate', 'of'), 24),\n",
              " (('<s>', 'the', 'imf'), 24),\n",
              " (('the', 'new', 'york'), 24),\n",
              " (('the', 'economy', '</s>'), 24),\n",
              " (('part', 'of', 'its'), 24),\n",
              " (('period', '</s>', '<s>'), 24),\n",
              " (('20', '</s>', '<s>'), 24),\n",
              " (('interest', 'rate', 'rises'), 24),\n",
              " (('is', 'trying', 'to'), 24),\n",
              " (('<s>', '<s>', 'after'), 24),\n",
              " (('chapter', '11', 'bankruptcy'), 24),\n",
              " (('but', 'it', 'is'), 24),\n",
              " (('of', 'the', 'disaster'), 24),\n",
              " (('<s>', 'for', 'the'), 22),\n",
              " (('the', 'us', 's'), 22),\n",
              " (('27', '</s>', '<s>'), 22),\n",
              " (('yugansk', '</s>', '<s>'), 22),\n",
              " (('founder', 'mikhail', 'khodorkovsky'), 22),\n",
              " (('<s>', '<s>', 'yet'), 22),\n",
              " (('in', 'the', 'previous'), 22),\n",
              " (('the', 'rise', 'in'), 22),\n",
              " (('production', '</s>', '<s>'), 22),\n",
              " (('that', 'the', 'us'), 22),\n",
              " (('money', '</s>', '<s>'), 22),\n",
              " (('it', 'has', 'been'), 22),\n",
              " (('<s>', 'the', 'eu'), 22),\n",
              " (('<s>', 'in', 'addition'), 22),\n",
              " (('earlier', 'this', 'year'), 22),\n",
              " (('the', 'firm', 'had'), 22),\n",
              " (('13', '</s>', '<s>'), 22),\n",
              " (('50', '</s>', '<s>'), 22),\n",
              " (('<s>', '<s>', '1m'), 22),\n",
              " (('<s>', 'meanwhile', 'the'), 22),\n",
              " (('the', 'rest', 'of'), 22),\n",
              " (('rest', 'of', 'the'), 22),\n",
              " (('economic', 'growth', 'in'), 22),\n",
              " (('fraud', 'and', 'tax'), 22),\n",
              " (('and', 'tax', 'evasion'), 22),\n",
              " (('<s>', 'mr', 'khodorkovsky'), 22),\n",
              " (('<s>', '5bn', '£'), 22),\n",
              " (('states', '</s>', '<s>'), 22),\n",
              " (('pointed', 'out', 'that'), 22),\n",
              " (('<s>', 'the', 'price'), 22),\n",
              " (('analysts', 'said', 'that'), 22),\n",
              " (('<s>', '<s>', 'japanese'), 22),\n",
              " (('over', 'the', 'last'), 22),\n",
              " (('he', 'added', 'that'), 22),\n",
              " (('<s>', '<s>', 'chinese'), 22),\n",
              " (('<s>', '<s>', 'speaking'), 22),\n",
              " (('<s>', '<s>', 'recent'), 22),\n",
              " (('that', 'the', 'economy'), 22),\n",
              " (('the', 'last', 'quarter'), 22),\n",
              " (('it', 'will', 'be'), 22),\n",
              " (('<s>', 'as', 'part'), 22),\n",
              " (('up', '</s>', '<s>'), 22),\n",
              " (('<s>', 'he', 'has'), 22),\n",
              " (('<s>', 'consumer', 'spending'), 22),\n",
              " (('<s>', 'south', 'korea'), 22),\n",
              " (('the', 'next', 'three'), 22),\n",
              " (('<s>', 'the', 'german'), 22),\n",
              " (('office', 'for', 'national'), 22),\n",
              " (('the', 'bank', 'said'), 22),\n",
              " (('it', 'is', 'to'), 22),\n",
              " (('<s>', '<s>', 'germany'), 22),\n",
              " (('the', 'state', 'of'), 22),\n",
              " (('world', 'trade', 'organisation'), 22),\n",
              " (('as', 'many', 'as'), 22),\n",
              " (('19', '</s>', '<s>'), 22),\n",
              " (('to', 'take', 'the'), 22),\n",
              " (('said', 'to', 'be'), 22),\n",
              " (('25', '</s>', '<s>'), 22),\n",
              " (('khodorkovsky', '</s>', '<s>'), 22),\n",
              " (('s', 'decision', 'to'), 22),\n",
              " (('<s>', '<s>', 'argentina'), 22),\n",
              " (('days', '</s>', '<s>'), 22),\n",
              " (('<s>', '<s>', 'bank'), 22),\n",
              " (('<s>', '<s>', 'instead'), 22),\n",
              " (('102', '</s>', '<s>'), 22),\n",
              " (('march', '</s>', '<s>'), 22),\n",
              " (('in', 'the', 'new'), 22),\n",
              " (('a', '1', '</s>'), 22),\n",
              " (('charges', '</s>', '<s>'), 22),\n",
              " (('on', 'the', 'news'), 22),\n",
              " (('rates', 'on', 'hold'), 22),\n",
              " (('seen', 'in', 'the'), 22),\n",
              " (('to', 'be', 'the'), 22),\n",
              " (('the', 'uk', '</s>'), 22),\n",
              " (('uk', '</s>', '<s>'), 22),\n",
              " (('between', 'the', 'two'), 22),\n",
              " (('the', 'company', 'and'), 22),\n",
              " (('the', 'country', '</s>'), 22),\n",
              " (('yuganskneftegas', '</s>', '<s>'), 22),\n",
              " (('control', 'of', 'the'), 22),\n",
              " (('stock', 'exchange', '</s>'), 22),\n",
              " (('to', 'make', 'a'), 22),\n",
              " (('deutsche', 'boerse', 's'), 22),\n",
              " (('<s>', '<s>', 'euronext'), 22),\n",
              " (('the', 'paris', 'club'), 22),\n",
              " (('<s>', '<s>', 'lg'), 22),\n",
              " (('revenues', '</s>', '<s>'), 20),\n",
              " (('in', 'a', 'deal'), 20),\n",
              " (('a', 'quarter', 'of'), 20),\n",
              " (('for', '9', '</s>'), 20),\n",
              " (('assets', '</s>', '<s>'), 20),\n",
              " (('an', 'attempt', 'to'), 20),\n",
              " (('<s>', 'the', 'sale'), 20),\n",
              " (('ambitions', 'of', 'its'), 20),\n",
              " (('to', '£', '1'), 20),\n",
              " (('forecast', '</s>', '<s>'), 20),\n",
              " (('year', 'to', 'march'), 20),\n",
              " (('recession', '</s>', '<s>'), 20),\n",
              " (('<s>', 'japan', 's'), 20),\n",
              " (('three', 'years', '</s>'), 20),\n",
              " (('of', 'the', 'dollar'), 20),\n",
              " (('workers', '</s>', '<s>'), 20),\n",
              " (('nations', '</s>', '<s>'), 20),\n",
              " (('<s>', 'he', 'also'), 20),\n",
              " (('<s>', '<s>', 'separately'), 20),\n",
              " (('decision', '</s>', '<s>'), 20),\n",
              " (('<s>', 'among', 'the'), 20),\n",
              " (('<s>', '<s>', 'indonesia'), 20),\n",
              " (('of', 'this', 'year'), 20),\n",
              " (('was', 'likely', 'to'), 20),\n",
              " (('the', 'past', 'year'), 20),\n",
              " (('<s>', 'last', 'month'), 20),\n",
              " (('added', 'that', 'the'), 20),\n",
              " (('<s>', '<s>', 'all'), 20),\n",
              " (('than', 'a', 'year'), 20),\n",
              " (('at', 'the', 'centre'), 20),\n",
              " (('in', 'the', 'same'), 20),\n",
              " (('<s>', '<s>', 's'), 20),\n",
              " (('2007', '</s>', '<s>'), 20),\n",
              " (('the', 'decision', 'to'), 20),\n",
              " (('operations', '</s>', '<s>'), 20),\n",
              " (('spokesman', 'for', 'the'), 20),\n",
              " (('comment', 'on', 'the'), 20),\n",
              " (('the', 'firm', 'is'), 20),\n",
              " (('pre', 'tax', 'profits'), 20),\n",
              " (('oil', 'prices', 'and'), 20),\n",
              " (('as', 'a', 'whole'), 20),\n",
              " (('output', '</s>', '<s>'), 20),\n",
              " (('by', '4', '</s>'), 20),\n",
              " (('<s>', '9', 'in'), 20),\n",
              " (('to', 'a', 'new'), 20),\n",
              " (('warned', '</s>', '<s>'), 20),\n",
              " (('problems', '</s>', '<s>'), 20),\n",
              " (('in', 'north', 'america'), 20),\n",
              " (('2010', '</s>', '<s>'), 20),\n",
              " (('action', '</s>', '<s>'), 20),\n",
              " (('forecasts', '</s>', '<s>'), 20),\n",
              " (('that', 'the', 'government'), 20),\n",
              " (('told', 'bbc', 'news'), 20),\n",
              " (('that', 'it', 'will'), 20),\n",
              " (('<s>', 'analysts', 'say'), 20),\n",
              " (('us', 'stock', 'market'), 20),\n",
              " (('to', 'meet', 'the'), 20),\n",
              " (('the', 'sec', 's'), 20),\n",
              " (('the', 'possibility', 'of'), 20),\n",
              " (('the', 'deal', '</s>'), 20),\n",
              " (('investors', '</s>', '<s>'), 20),\n",
              " (('a', '0', '</s>'), 20),\n",
              " (('<s>', 'oil', 'prices'), 20),\n",
              " (('figures', 'from', 'the'), 20),\n",
              " (('year', 'ago', '</s>'), 20),\n",
              " (('first', 'quarter', 'of'), 20),\n",
              " (('most', 'of', 'the'), 20),\n",
              " (('in', 'the', 'next'), 20),\n",
              " (('<s>', 'the', 'news'), 20),\n",
              " (('the', 'office', 'for'), 20),\n",
              " (('in', 'the', 'housing'), 20),\n",
              " (('<s>', '<s>', 'two'), 20),\n",
              " (('figures', '</s>', '<s>'), 20),\n",
              " (('<s>', '<s>', 'european'), 20),\n",
              " (('<s>', '<s>', 'profits'), 20),\n",
              " (('<s>', '<s>', 'of'), 20),\n",
              " (('<s>', 'the', 'main'), 20),\n",
              " (('of', 'the', 'euro'), 20),\n",
              " (('same', 'period', 'in'), 20),\n",
              " (('has', 'been', 'a'), 20),\n",
              " (('year', 'on', 'year'), 20),\n",
              " (('in', 'december', '</s>'), 20),\n",
              " (('the', 'two', 'companies'), 20),\n",
              " (('mikhail', 'khodorkovsky', '</s>'), 20),\n",
              " (('3bn', '</s>', '<s>'), 20),\n",
              " (('bill', '</s>', '<s>'), 20),\n",
              " (('<s>', 'deutsche', 'bank'), 20),\n",
              " (('in', 'the', 'case'), 20),\n",
              " (('from', 'the', 'us'), 20),\n",
              " (('of', 'russia', 's'), 20),\n",
              " (('interest', '</s>', '<s>'), 20),\n",
              " (('an', 'annual', 'rate'), 20),\n",
              " (('the', 'company', 'is'), 20),\n",
              " (('with', 'the', 'us'), 20),\n",
              " (('<s>', 'mr', 'sullivan'), 20),\n",
              " (('talks', 'with', 'the'), 20),\n",
              " (('share', '</s>', '<s>'), 20),\n",
              " (('<s>', 'the', 'commission'), 20),\n",
              " (('less', 'than', 'the'), 20),\n",
              " (('we', 'don', 't'), 20),\n",
              " (('of', 'india', 's'), 20),\n",
              " (('going', 'to', 'be'), 20),\n",
              " (('<s>', '<s>', 'ukraine'), 20),\n",
              " (('chief', 'executive', 'of'), 20),\n",
              " (('<s>', 'yukos', 'has'), 20),\n",
              " (('<s>', '<s>', 'mci'), 20),\n",
              " (('the', 'club', '</s>'), 20),\n",
              " (('in', 'october', '</s>'), 20),\n",
              " (('<s>', 'with', 'the'), 20),\n",
              " (('<s>', '<s>', 'companies'), 20),\n",
              " (('<s>', '<s>', 'thailand'), 20),\n",
              " (('profit', '</s>', '<s>'), 18),\n",
              " (('on', 'the', 'back'), 18),\n",
              " (('by', 'the', 'us'), 18),\n",
              " (('results', '</s>', '<s>'), 18),\n",
              " (('chairman', 'and', 'chief'), 18),\n",
              " (('a', 'deal', 'with'), 18),\n",
              " (('sale', 'of', 'its'), 18),\n",
              " (('the', 'us', 'government'), 18),\n",
              " (('concerns', 'about', 'the'), 18),\n",
              " (('for', 'some', 'time'), 18),\n",
              " (('bank', 'of', 'america'), 18),\n",
              " (('this', 'year', 'and'), 18),\n",
              " (('oil', 'giant', 'yukos'), 18),\n",
              " (('in', 'an', 'attempt'), 18),\n",
              " (('for', 'the', 'political'), 18),\n",
              " (('of', 'its', 'founder'), 18),\n",
              " (('its', 'founder', 'mikhail'), 18),\n",
              " (('<s>', '3', 'to'), 18),\n",
              " (('to', '3', '</s>'), 18),\n",
              " (('the', 'impact', 'of'), 18),\n",
              " (('in', 'the', 'united'), 18),\n",
              " (('a', 'third', 'of'), 18),\n",
              " (('<s>', '<s>', 'nevertheless'), 18),\n",
              " (('election', '</s>', '<s>'), 18),\n",
              " (('000', '</s>', '<s>'), 18),\n",
              " (('we', 'are', 'not'), 18),\n",
              " (('country', 's', 'economic'), 18),\n",
              " (('s', 'economic', 'growth'), 18),\n",
              " (('<s>', 'the', 'report'), 18),\n",
              " (('would', 'have', 'to'), 18),\n",
              " (('have', 'to', 'be'), 18),\n",
              " (('she', 'said', '</s>'), 18),\n",
              " (('for', 'the', 'firm'), 18),\n",
              " (('japan', '</s>', '<s>'), 18),\n",
              " (('<s>', 'they', 'have'), 18),\n",
              " (('news', 'of', 'the'), 18),\n",
              " (('compensation', '</s>', '<s>'), 18),\n",
              " (('programme', '</s>', '<s>'), 18),\n",
              " (('the', 'centre', 'of'), 18),\n",
              " (('<s>', 'on', 'tuesday'), 18),\n",
              " (('1', 'in', 'the'), 18),\n",
              " (('to', 'increase', 'the'), 18),\n",
              " (('<s>', '<s>', 'you'), 18),\n",
              " (('move', '</s>', '<s>'), 18),\n",
              " (('abroad', '</s>', '<s>'), 18),\n",
              " (('21', '</s>', '<s>'), 18),\n",
              " (('in', 'november', 'to'), 18),\n",
              " (('of', '0', '</s>'), 18),\n",
              " (('would', 'be', 'the'), 18),\n",
              " (('the', 'new', 'year'), 18),\n",
              " (('of', 'last', 'year'), 18),\n",
              " (('policies', '</s>', '<s>'), 18),\n",
              " (('taxes', '</s>', '<s>'), 18),\n",
              " (('protection', '</s>', '<s>'), 18),\n",
              " (('from', '2', '</s>'), 18),\n",
              " (('in', '2006', '</s>'), 18),\n",
              " (('the', 'world', 'economy'), 18),\n",
              " (('at', 'the', 'start'), 18),\n",
              " (('55', '</s>', '<s>'), 18),\n",
              " (('<s>', '<s>', 'several'), 18),\n",
              " (('investments', '</s>', '<s>'), 18),\n",
              " (('s', '</s>', '<s>'), 18),\n",
              " (('problem', '</s>', '<s>'), 18),\n",
              " (('cuts', '</s>', '<s>'), 18),\n",
              " (('reports', '</s>', '<s>'), 18),\n",
              " (('the', 'long', 'term'), 18),\n",
              " (('<s>', '<s>', 'over'), 18),\n",
              " (('i', 'don', 't'), 18),\n",
              " (('as', 'the', 'world'), 18),\n",
              " (('s', 'richest', 'man'), 18),\n",
              " (('a', 'time', 'when'), 18),\n",
              " (('better', 'than', 'expected'), 18),\n",
              " (('<s>', '<s>', 'net'), 18),\n",
              " (('higher', '</s>', '<s>'), 18),\n",
              " (('agreed', 'to', 'buy'), 18),\n",
              " (('<s>', '<s>', '7m'), 18),\n",
              " (('the', 'launch', 'of'), 18),\n",
              " (('<s>', '<s>', '6m'), 18),\n",
              " (('the', 'business', '</s>'), 18),\n",
              " (('say', '</s>', '<s>'), 18),\n",
              " (('in', 'consumer', 'spending'), 18),\n",
              " (('later', 'this', 'year'), 18),\n",
              " (('by', 'the', 'government'), 18),\n",
              " (('in', 'the', 'value'), 18),\n",
              " (('the', 'outlook', 'for'), 18),\n",
              " (('first', 'time', 'in'), 18),\n",
              " (('recent', 'years', '</s>'), 18),\n",
              " (('will', 'continue', 'to'), 18),\n",
              " (('<s>', 'the', 'airline'), 18),\n",
              " (('to', 'more', 'than'), 18),\n",
              " (('the', 'firm', '</s>'), 18),\n",
              " (('listing', '</s>', '<s>'), 18),\n",
              " (('businesses', '</s>', '<s>'), 18),\n",
              " (('<s>', 'it', 'added'), 18),\n",
              " (('previous', 'year', '</s>'), 18),\n",
              " (('for', 'national', 'statistics'), 18),\n",
              " (('<s>', 'the', 'ons'), 18),\n",
              " (('interest', 'rates', 'are'), 18),\n",
              " (('the', 'collapse', 'of'), 18),\n",
              " (('said', 'he', 'was'), 18),\n",
              " (('in', 'a', 'row'), 18),\n",
              " (('firm', 'said', 'it'), 18),\n",
              " (('had', 'been', 'expected'), 18),\n",
              " (('is', 'thought', 'to'), 18),\n",
              " (('aircraft', '</s>', '<s>'), 18),\n",
              " (('<s>', '<s>', 'airbus'), 18),\n",
              " (('the', 'us', 'is'), 18),\n",
              " (('said', 'it', 'expected'), 18),\n",
              " (('period', 'in', '2003'), 18),\n",
              " (('the', 'central', 'bank'), 18),\n",
              " (('rise', 'in', 'the'), 18),\n",
              " (('spending', '</s>', '<s>'), 18),\n",
              " (('said', 'on', 'tuesday'), 18),\n",
              " (('levels', '</s>', '<s>'), 18),\n",
              " (('in', 'the', 'future'), 18),\n",
              " (('tax', 'bill', '</s>'), 18),\n",
              " (('up', 'in', 'the'), 18),\n",
              " (('<s>', 'analysts', 'have'), 18),\n",
              " (('oil', '</s>', '<s>'), 18),\n",
              " (('£', '7', '</s>'), 18),\n",
              " (('it', 'was', 'a'), 18),\n",
              " (('the', 'dollar', 'was'), 18),\n",
              " (('president', 'vladimir', 'putin'), 18),\n",
              " (('out', 'of', 'a'), 18),\n",
              " (('in', 'the', 'final'), 18),\n",
              " (('<s>', '<s>', '8m'), 18),\n",
              " (('monday', '</s>', '<s>'), 18),\n",
              " (('<s>', '<s>', 'marsh'), 18),\n",
              " (('the', 'commission', 's'), 18),\n",
              " (('spokesman', '</s>', '<s>'), 18),\n",
              " (('<s>', 'in', 'contrast'), 18),\n",
              " (('securities', '</s>', '<s>'), 18),\n",
              " (('there', 'was', 'no'), 18),\n",
              " (('next', 'year', '</s>'), 18),\n",
              " (('<s>', '<s>', 'barclays'), 18),\n",
              " (('was', 'one', 'of'), 18),\n",
              " (('services', '</s>', '<s>'), 18),\n",
              " (('<s>', '<s>', 'gazprom'), 18),\n",
              " (('of', 'the', 'deal'), 18),\n",
              " (('the', 'beginning', 'of'), 18),\n",
              " (('<s>', '<s>', 'house'), 18),\n",
              " (('<s>', 'house', 'prices'), 18),\n",
              " (('price', '</s>', '<s>'), 18),\n",
              " (('<s>', '5', 'to'), 18),\n",
              " (('this', '</s>', '<s>'), 18),\n",
              " (('parts', 'of', 'the'), 18),\n",
              " (('against', 'the', 'dollar'), 18),\n",
              " (('much', 'of', 'the'), 18),\n",
              " (('in', 'hong', 'kong'), 18),\n",
              " (('the', 'club', 's'), 18),\n",
              " (('talks', '</s>', '<s>'), 18),\n",
              " (('<s>', 'the', 'club'), 18),\n",
              " (('the', 'ftse', '100'), 18),\n",
              " (('s', 'economy', 'is'), 18),\n",
              " (('currency', '</s>', '<s>'), 18),\n",
              " (('cost', 'of', 'the'), 18),\n",
              " (('impact', '</s>', '<s>'), 18),\n",
              " (('<s>', '<s>', 'wal'), 18),\n",
              " (('<s>', 'wal', 'mart'), 18),\n",
              " (('the', 'back', 'of'), 16),\n",
              " (('revenue', '</s>', '<s>'), 16),\n",
              " (('the', 'dollar', 'has'), 16),\n",
              " (('new', 'york', '</s>'), 16),\n",
              " (('york', '</s>', '<s>'), 16),\n",
              " (('and', 'the', 'us'), 16),\n",
              " (('<s>', '<s>', 'rosneft'), 16),\n",
              " (('banks', '</s>', '<s>'), 16),\n",
              " (('for', 'bankruptcy', 'protection'), 16),\n",
              " (('in', 'a', 'us'), 16),\n",
              " (('yugansk', 'was', 'sold'), 16),\n",
              " (('which', 'in', 'turn'), 16),\n",
              " (('<s>', '3', '</s>'), 16),\n",
              " (('to', 'march', '2005'), 16),\n",
              " (('the', '11', 'september'), 16),\n",
              " (('target', 'of', 'a'), 16),\n",
              " (('the', 'brink', 'of'), 16),\n",
              " (('2', 'in', 'the'), 16),\n",
              " (('to', 'do', 'so'), 16),\n",
              " (('environment', '</s>', '<s>'), 16),\n",
              " (('<s>', 'in', 'london'), 16),\n",
              " (('the', 'united', 'nations'), 16),\n",
              " (('24', '</s>', '<s>'), 16),\n",
              " (('<s>', 'in', '2003'), 16),\n",
              " (('<s>', '2', 'million'), 16),\n",
              " (('system', '</s>', '<s>'), 16),\n",
              " (('country', 's', 'biggest'), 16),\n",
              " (('<s>', 'they', 'also'), 16),\n",
              " (('<s>', '<s>', 'millions'), 16),\n",
              " (('it', 'wants', 'to'), 16),\n",
              " (('that', 'there', 'was'), 16),\n",
              " (('the', 'two', 'firms'), 16),\n",
              " (('the', 'company', 'had'), 16),\n",
              " (('<s>', '2bn', '£'), 16),\n",
              " (('<s>', 'they', 'are'), 16),\n",
              " (('not', 'have', 'to'), 16),\n",
              " (('in', 'a', 'bid'), 16),\n",
              " (('a', 'bid', 'to'), 16),\n",
              " (('for', 'more', 'than'), 16),\n",
              " (('do', 'not', 'have'), 16),\n",
              " (('<s>', 'on', 'wednesday'), 16),\n",
              " ...]"
            ]
          },
          "execution_count": 339,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lm.n_grams_counts.most_common()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ba8069",
      "metadata": {
        "id": "14ba8069"
      },
      "source": [
        "## Part 2: Written [40 points]. We have given some code for some of the written parts to make it easier for you."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53431996",
      "metadata": {
        "id": "53431996"
      },
      "source": [
        "### **Written 3.3** – Song Attribution [8 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "id": "4751ea5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4751ea5b",
        "outputId": "09ecb62d-bafa-477f-c191-4f5d3512b662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "522.5401188730924\n"
          ]
        }
      ],
      "source": [
        "# Example code for Taylor Swift LM\n",
        "n = 3\n",
        "smoothing = 0.1\n",
        "min_freq = 1\n",
        "\n",
        "train = read_file(\"data/lyrics/green_day.txt\")\n",
        "test = read_file(\"data/lyrics/test_lyrics.txt\")\n",
        "\n",
        "train = preprocess(train, n)\n",
        "test = preprocess(test, n)\n",
        "lm = LanguageModel(n, train, smoothing)\n",
        "\n",
        "ppl = perplexity(lm, test)\n",
        "print(ppl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749a49a0",
      "metadata": {
        "id": "749a49a0"
      },
      "source": [
        "### **Written 3.4.1** –  Intro to Decoding [8 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "id": "c8ed9b85",
      "metadata": {
        "id": "c8ed9b85"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "smoothing = 0.1\n",
        "min_freq = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "id": "96b3d000",
      "metadata": {
        "id": "96b3d000"
      },
      "outputs": [],
      "source": [
        "train = read_file(\"data/bbc/entertainment.txt\")\n",
        "train = preprocess(train, n)\n",
        "\n",
        "lm = LanguageModel(n, train, smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "id": "17794ab7",
      "metadata": {
        "id": "17794ab7"
      },
      "outputs": [],
      "source": [
        "s1 = (\"number\", \"three\")\n",
        "\n",
        "s2 = (\"starred\", \"in\")\n",
        "\n",
        "s3 = (\"actor\", \"in\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "id": "69ef66a2",
      "metadata": {
        "id": "69ef66a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('a', 0.005177389237820403), ('2004', 0.0009336275674758106)]"
            ]
          },
          "execution_count": 348,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO Get the top 5 candidates for next best word\n",
        "top_k_best_candidates(lm, s3, 5, without=['<s>', '</s>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee4e956",
      "metadata": {
        "id": "8ee4e956"
      },
      "source": [
        "### **Written 3.4.2** – Text Generation [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "205129a7",
      "metadata": {
        "id": "205129a7"
      },
      "source": [
        "For this subtask, use the LM trained in Written 3.4.1\n",
        "\n",
        "Selecting words sequentially from a probability distribution is called _decoding_.\n",
        "\n",
        "Two popular decoding approaches are,\n",
        "1. **Max-probability decoding** - We consistently choose the candidate with maximum probability.\n",
        "2. **Random Sampling** - We sample a candidate randomly.\n",
        "2. **top-K Sampling** - We sample a candidate randomly from the top-K most probable choices.\n",
        "\n",
        "In this part, we will try the first two approaches to generate sentences.\n",
        "\n",
        "Q1. Use `generate_sentences()` method to generate sentences after the provided phrases from `s1` to `s3`. Use modes `random` and `max`. Report one of your favourite generations (for any strategy or phrase). Which mode you think is better and why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "id": "dcd3a291",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcd3a291",
        "outputId": "803606c0-975f-441f-b881-b0cbbdeb80dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('<s> <s> number three during its first week on home entertainment release the film s director richard eyre issued a warning earlier in his </s>', 0.007691174546401956)]\n",
            "[('<s> <s> number three during its first week on home entertainment release the film s director richard eyre issued a warning earlier in his </s>', 0.007691174546401956)]\n",
            "[('<s> <s> number three during its first week on home entertainment release the film s director richard eyre issued a warning earlier in his </s>', 0.007691174546401956)]\n",
            "[('<s> <s> number three during its first week on home entertainment release the film s director richard eyre issued a warning earlier in his </s>', 0.007691174546401956)]\n",
            "[('<s> <s> number three during its first week on home entertainment release the film s director richard eyre issued a warning earlier in his </s>', 0.007691174546401956)]\n"
          ]
        }
      ],
      "source": [
        "# Random\n",
        "for _ in range(5):\n",
        "    print(list(generate_sentences_from_phrase(lm, 1, [\"<s>\", \"<s>\", \"number\", \"three\"], 0.2, mode=\"max\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d712619f",
      "metadata": {
        "id": "d712619f"
      },
      "source": [
        "**Aside (for fun!)**: Train your LM on Taylor Swift lyrics and generate the next hit!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b9047d",
      "metadata": {
        "id": "17b9047d"
      },
      "source": [
        "### **Written 3.5** – Battle of the LMs: GPT-2 vs Trigram [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d38359",
      "metadata": {
        "id": "41d38359"
      },
      "source": [
        "For this subtask, you will be generating text and comparing GPT-2 with your n-gram language model. \n",
        "\n",
        "Generative pretrained transformer (GPT) is a neural language model series created by OpenAI. The n-gram language model you trained has on average around 10K-20K parameters (`len(lm.model)`.) Compare that to the 175 billion parameters of the latest version of GPT-3!\n",
        "\n",
        "Let's see how GPT-2 compares to the LM you trained in subtask 4 on `data/bbc/tech-small.txt` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "id": "e143e87c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e143e87c",
        "outputId": "c429800e-7cb2-4ce2-e25f-e9d349422a66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4889.176510567337\n"
          ]
        }
      ],
      "source": [
        "test = read_file(\"data/bbc/tech-small.txt\")\n",
        "test = preprocess(test, n)\n",
        "lm = LanguageModel(n, train, smoothing)\n",
        "ppl = perplexity(lm, test)\n",
        "print(ppl)\n",
        "#TODO: Calculate your n-gram model's perplexity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db542ceb",
      "metadata": {
        "id": "db542ceb"
      },
      "source": [
        "### Computing GPT-2's perplexity on test set\n",
        "\n",
        "You need to enable a GPU runtime from `Runtime` menu option. Go to `Runtime` → `Change Runtime Type` → `Hardware Accelerator (GPU)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "d6501dcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6501dcd",
        "outputId": "d01f3383-831f-4b1f-ff59-c8a70e4b8e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "Requirement already satisfied: transformers in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (4.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (2020.10.15)\n",
            "Requirement already satisfied: importlib-metadata in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/jwa/.local/lib/python3.7/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from transformers) (1.21.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from requests->transformers) (2022.5.18.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "Requirement already satisfied: torch in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (1.8.1)\n",
            "Requirement already satisfied: typing_extensions in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (from torch) (1.21.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "Requirement already satisfied: tqdm in /opt/anaconda3/envs/NLP/lib/python3.7/site-packages (4.63.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymssql (/opt/anaconda3/envs/NLP/lib/python3.7/site-packages)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "id": "Ldf6ovg4B5Qc",
      "metadata": {
        "id": "Ldf6ovg4B5Qc"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "import torch\n",
        "\n",
        "model_id = \"distilgpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "id": "67zwTHSI0hCC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67zwTHSI0hCC",
        "outputId": "0130ddd6-c2e3-4b57-c6ae-11b39e5a8703"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "test = read_file(\"data/bbc/tech-small.txt\")\n",
        "encodings = tokenizer(\"\\n\\n\".join(test), return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "id": "wmQKbMXjDFNj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmQKbMXjDFNj",
        "outputId": "d28c273f-7b74-4d38-e9c3-16e982aebf2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:18<00:00,  1.56s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "max_length = model.config.n_positions\n",
        "stride = 100\n",
        "\n",
        "nlls = []\n",
        "for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
        "    begin_loc = max(i + stride - max_length, 0)\n",
        "    end_loc = min(i + stride, encodings.input_ids.size(1))\n",
        "    trg_len = end_loc - i  # may be different from stride on last loop\n",
        "    input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        neg_log_likelihood = outputs[0] * trg_len\n",
        "\n",
        "    nlls.append(neg_log_likelihood)\n",
        "\n",
        "ppl = torch.exp(torch.stack(nlls).sum() / end_loc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "id": "giXGq0Z0DWdr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giXGq0Z0DWdr",
        "outputId": "cfc34c8b-5850-4c51-a926-148045f4e51f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity using GPT2: 50.644840240478516\n"
          ]
        }
      ],
      "source": [
        "print(\"Perplexity using GPT2:\", ppl.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "a5ZGKl-6s3AF",
      "metadata": {
        "id": "a5ZGKl-6s3AF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('NLP')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "60951fe2ccac1c258907b209f658f6ef884c93d9ccb3f36667a6035df696e51a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
